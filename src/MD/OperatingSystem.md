# 操作系统相关知识

### 自旋锁（SpinLock）
有种 try_lock 的赶脚
自旋锁是专为防止多处理器并发而引入的一种锁。如果是单核处理器，则自旋锁定义为空操作，因为简单的关闭中断即可实现互斥。
自旋锁最多只能被一个线程持有，如果一个线程试图请求一个已被争用(已被另一个线程持有)的自旋锁，那么等待自旋锁的线程将会
`反复检查自旋锁是否释放`，不会进入睡眠状态，一直处于`忙等待状态(busy-waiting)`，直到获取该自旋锁才能继续执行未完成的任务，
所以常用于短期保护某段代码。
另外，持有自旋锁的进程也不允许睡眠，不然会造成死锁——因为睡眠可能造成持有锁的进程被重新调度，而再次申请自己已持有的锁。
 
事实上，自旋锁的初衷就是：`在短期间内进行轻量级的锁定`。一个被争用的自旋锁使得请求它的线程在等待锁重新可用的期间进行自旋(特别浪费处理器时间)，所以自旋锁不应该被持有时间过长。如果需要长时间锁定的话, 最好使用信号量。
 
自旋锁的基本形式如下：
```
spin_lock(&mr_lock);
//临界区
spin_unlock(&mr_lock);
```
同一时刻只有一个线程允许处于临界区中，可用来防止多处理器中并发访问临界区，抢占共享资源造成的竞争。

### 信号量(Semaphore)
信号量是一种机制。在进入一个关键代码段之前，线程必须获取一个信号量；一旦执行完该关键代码段，则释放获取的信号量。
如果获取不到信号量，则进入等待队列，并保持休眠状态(sleep-waiting)，此时，`线程释放占用的处理器`，以便处理器执行其它任务。
当有未被持有的信号量时，唤醒队列中的线程，线程从而获取信号量，继续执行未完成的任务。
`p操作（wait）`：申请一个单位资源，进程进入
`v操作（signal）`：释放一个单位资源，进程出来

### 互斥量（Mutex）
同临界区有些类似，只有拥有互斥对象(即互斥量)的线程才具有访问共享资源的权限，由于互斥对象只有一个，因此就决定了任何情况下此共享资源都不会同时被多个线程所访问。
当占据资源的线程在任务处理完任务后应释放占有的的互斥对象，以便其他线程在获得该互斥对象后得以访问资源。

### 信号量与互斥量
#### 互斥量与信号量的区别？
 (1) 互斥量用于`线程的互斥`，信号量用于`线程的同步`
这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别
 
互斥：是指某一资源同时`只允许一个访问者对其进行访问`，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的
 
同步：是指在互斥的基础上（大多数情况），通过其它机制`实现访问者对资源的有序访问`。在大多数情况下，`同步已经实现了互斥`，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
 
(2) 互斥量值只能为0/1，信号量值可以为非负整数
也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问

(3) 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到

### 临界区（Critical Section）
在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问同一临界区，那么在有一个线程进入后其他所有试图访问此临界区的
线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的。

### 死锁
是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去,陷入死循环。
假设有一个或多个内核任务和一个或多个资源，每个内核都在等待其中的一个资源，但所有的资源都已经被占用了，也就是说。这便会发生所有内核任
务都在相互等待，但它们永远不会释放已经占有的资源，于是任何内核任务都无法获得所需要的资源，无法继续运行，这便意味着死锁发生了。自死琐
是说自己占有了某个资源，然后自己又申请自己已占有的资源，显然不可能再获得该资源，因此就自缚手脚了。

#### 死锁的四个必要条件
`（1）互斥条件`：一个资源每次只能被一个进程使用。  
`（2）请求与保持条件`：一个进程因请求资源而阻塞时，对已获得的资源保持不放。  
`（3）不剥夺条件`:进程已获得的资源，在末使用完之前，不能强行剥夺。  
`（4）循环等待条件`:若干进程之间形成一种头尾相接的循环等待资源关系。

#### 解决死锁的策略
`(1) 死锁预防`：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，
这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。
`(2) 死锁避免`：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用银行家算法。死锁避免算法的执行会增加系统的开销。
`(3) 死锁检测`：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。
`(4) 死锁解除`：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。

### 进程和线程的区别？
进程和线程的主要差别在于它们是不同的操作系统资源管理方式。`进程有独立的地址空间，`一个进程崩溃后，在保护模式下不会对其它进程产生影响，
而线程只是一个进程中的不同执行路径。`线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉`，
所以多进程的程序要比多线程的程序健壮，但在`进程切换时，耗费资源较大`，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，
只能用线程，不能用进程。
定义方面：进程是程序在某个数据集合上的一次运行活动；线程是进程中的一个执行路径。
角色方面：在支持线程机制的系统中，`进程是系统资源分配的单位`，`线程是系统调度的单位`。
资源共享方面：进程之间不能共享资源，而线程共享所在进程的地址空间和其它资源。同时`线程还有自己的栈和栈指针，程序计数器等寄存器`。
独立性方面：`进程有自己独立的地址空间，而线程没有，线程必须依赖于进程而存在`。
1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.
2) 线程的划分尺度小于进程，使得`多线程程序的并发性高。`
3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。
4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。

维度                            多进程                         多线程                             总结

数据共享、同步         数据是分开的:共享复杂，                   多线程共享进程数据：
                         需要用IPC;同步简单                    共享简单；同步复杂                 各有优势

内存、CPU          占用内存多，切换复杂，CPU利用率低          `占用内存少，切换简单，CPU利用率高 `      线程占优

创建销毁、切换             创建销毁、切换复杂，速度慢           创建销毁、切换简单，速度快               线程占优 

编程调试                    编程简单，调试简单                   编程复杂，调试复杂                       进程占优 

可靠性                     进程间不会相互影响                   `一个线程挂掉将导致整个进程挂掉  `           进程占优

分布式             适应于多核、多机分布；如果一台机器不够，
                        扩展到多台机器比较简单                     适应于多核分布                         进程占优

父子进程之间的区别：    fork的返回值(=0子进程)；  进程ID不同；      
子线程特有的：线程ID；一组寄存器值；栈；线程私有数据；
                     
1)需要频繁创建销毁的优先用线程。
实例：web服务器。来一个建立一个线程，断了就销毁线程。要是用进程，创建和销毁的代价是很难承受的。
2）需要进行大量计算的优先使用线程。
所谓大量计算，当然就是要消耗很多cpu，切换频繁了，这种情况先线程是最合适的。
实例：图像处理、算法处理
3）强相关的处理用线程，若相关的处理用进程。
什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。
一般的server需要完成如下任务：消息收发和消息处理。消息收发和消息处理就是弱相关的任务，而消息处理里面可能又分为消息解码、业务处理，这两个任务相对来说相关性就要强多了。因此消息收发和消息处理可以分进程设计，消息解码和业务处理可以分线程设计。

### 信号
软中断信号（signal，又简称为信号）用来通知进程发生了异步事件。
进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发
送信号，通知进程发生了某个事件。注意，信号只是用来通知某进程发生了什么事件，并不给该
进程传递任何数据。 
#### 信号的系统调用 
1、signal 系统调用   系统调用signal用来设定某个信号的处理方法。
signal(SIGHUP, sigroutine); //* 下面设置三个信号的处理方法 
signal(SIGINT, sigroutine); 
signal(SIGQUIT, sigroutine); 
2、kill 系统调用     系统调用kill用来向进程发送一个信号。
3、pause系统调用     系统调用pause的作用是等待一个信号。

#### exit()与_exit()的区别？
`_exit终止调用进程，但不关闭文件，不清除输出缓存，也不调用出口函数。`exit函数将终止调用
进程。在退出程序之前，所有文件关闭，缓冲输出内容将刷新定义，并调用所有已刷新的“出口函数”
（由atexit定义）。
#### 如何实现守护进程？
守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进程。

## 通信
### 进程间通信
进程的通信机制主要有：管道、有名管道、消息队列、信号量、共享空间、信号、套接字。
#### 1.信号
信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程
不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。信号是进程间通信机制中唯一的异步通信机制，可以看作是异步
通知，通知接收信号的进程有哪些事情发生了。信号机制经过POSIX实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。信号事
件的发生有两个来源：硬件来源(比如我们按下了键盘或者其它硬件故障)；软件来源。
信号分为可靠信号和不可靠信号，实时信号和非实时信号。
进程有三种方式响应信号：忽略信号 捕捉信号 执行缺省操作
#### 2.信号量(sem)
`信号量也可以说是一个计数器`，常用来处理进程或线程同步的问题，特别是对临界资源的访问同步问题。临界资源：为某一时刻只能由一个进程或线程
操作的资源，当信号量的值大于或等于0时，表示可以供并发进程访问的临界资源数，当小于0时，表示正在等待使用临界资源的进程数。更重要的是，
信号量的值仅能由PV操作来改变。
为什仫要使用信号量？ 
为了防止出现因多个程序同时访问一个共享资源而引发的一系列问题，我们需要一种方法，它可以通过生成并使用令牌来授权，在任一时刻只能有一个执行线程访问代码的临界区域。 
什么是临界区？什么是临界资源？ 
临界资源：一次只允许一个进程使用的资源。 
临界区：访问临界资源的程序代码片段。 
信号量的工作原理？ 
P(wait)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行等待操作； 
V(signal)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1；
#### 3.消息队列
`消息队列是存放在内核中的消息链表`，每个消息队列由消息队列标识符标识，于管道不同的是，消息队列存放在内核中，只有在内核重启时才能删除一
个消息队列，内核重启也就是系统重启，同样消息队列的大小也是受限制的。
顾名思义，消息队列就是消息的链表，位于内核中。`消息队列中每个数据块都被认为是有一个类型，接收者进程接收的数据块可以有不同的类型值。`
`消息队列是基于消息的，管道是基于字节流的`,且消息队列的读取不一定是先入先出。。。
`管道的生命周期是随进程的，只要该进程消亡了该管道就会随之消失。但是消息队列却是随内核的，即使该进程消亡了该内核中的消息队列是不会主动消失的`
#### 4.共享内存
共享内存就是分配一块能被其他进程访问的内存。共享内存可以说是最有用的进程间通信方式，也是`最快的IPC`形式。首先说下在使用共享内存区前，
必须通过系统函数将其附加到进程的地址空间或说为映射到进程空间。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到 进程A、B各自
的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。
对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而 共享内存则只拷贝两次数据[1]：一次从输入文件到共享内存区，
另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就 解除映射，有新的通信时，再重新建立共享内存区域。
而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存 中的内容往往是在解除映射时才写回文件的。
因此，采用共享内存的通信方式效率是非常高的。

###### 管道、FIFO、消息队列的涉及到四次拷贝
1.服务器从输入文件读，该文件的数据由内核读入`自己的内存空间`
2.服务器往一个管道、FIFO或消息队列以一条消息的形式写入这些数据。这些IPC形式的通常需要把这些数据从进程`复制到内核`
3.客户从该IPC通道读出这些数据，这通常要把这些数据从`内核复制到进程`
4最后，将这些数据从由`write函数的第二个参数指定的客户缓冲区复制到输出文件。`

###### 共享内存只涉及到两次拷贝
共享内存区是可用IPC(Inter Process Communication 进程通信)形式中最快的，一旦这样的内存区映射共享它的进程的地址空间，
这些进程间的数据传递就`不再涉及内核了`
所以共享内存只涉及到两次拷贝，且只是在用户空间的拷贝


#### 5.管道
管道传递数据是单向性的，只能从一方流向另一方，也就是一种半双工的通信方式；只用于有亲缘关系的进程间的通信，亲缘关系也就是父子进程或
兄弟进程；没有名字并且大小受限，传输的是无格式的流，所以两进程通信时必须约定好数据通信的格式。管道它就像一个特殊的文件，但这个文件之
存在于内存中，在创建管道时，系统为管道分配了一个页面作为数据缓冲区，进程对这个数据缓冲区进行读写，以此来完成通信。其中一个进程只能读
一个只能写，所以叫半双工通信，为什么一个只能读一个只能写呢?因为写进程是在缓冲区的末尾写入，读进程是在缓冲区的头部读取，他们各自的数
据结构不同，所以功能不同。
##### 管道出现的四种特殊情况： 
1.写端关闭，读端不关闭； 
那么管道中剩余的数据都被读取后,再次read会返回0,就像读到文件末尾一样。 
2.写端不关闭，但是也不写数据，读端不关闭； 
此时管道中剩余的数据都被读取之后再次read会被阻塞，直到管道中有数据可读了才重新读取数据并返回； 
3.`读端关闭，写端不关闭；` 
此时该进程会收到信号SIGPIPE，通常会导致`进程异常终止`。 
4.读端不关闭，但是也不读取数据，写端不关闭； 
此时当写端被写满之后再次write会阻塞，直到管道中有空位置了才会写入数据并重新返回。 
使用管道的缺点： 
1.两个进程通过一个管道只能实现`单向通信`，如果想双向通信必须再重新创建一个管道或者使用sockpair才可以解决这类问题； 
2.`只能用于具有亲缘关系的进程间通信，例如父子，兄弟进程。` 
#### 6.命名管道(FIFO)
命名管道(NamedPipe)是服务器进程和一个或多个客户进程之间通信的单向或双向管道。不同于匿名管道的是：命名管道可以在不相关的进程之间和不
同计算机之间使用，服务器建立命名管道时给它指定一个名字，任何进程都可以通过该名字打开管道的另一端，根据给定的权限和服务器进程通信。
命名管道提供了相对简单的编程接口，使通过网络传输数据并不比同一计算机上两进程之间通信更困难，不过如果要同时和多个进程通信它就力不从心了。
命名管道不同与管道只能在具有亲缘关系的进程间通信了。它提供了一个路径名与之关联，有了自己的传输格式。
命名管道和管道的不同之处还有一点是,`有名管道是个设备文件，存储在文件系统中，没有亲缘关系的进程也可以访问，但是它要按照先进先出的原则
读取数据`。同样也是`单双工的`。
###### 命名管道的特点： 
1.`命名管道是一个存在于硬盘上的文件`，`而管道是存在于内存中的特殊文件`。所以当使用命名管道的时候必须先open将其打开。 
2.命名管道可以用于任何两个进程之间的通信，不管这两个进程是不是父子进程，也不管这两个进程之间有没有关系。 
#### 7.套接字
套接字也是一种进程间通信机制，与其他通信机制不同的是，`它可用于不同主机间的进程通信。`

### 线程间通信
线程间通信：由于多线程共享地址空间和数据空间，所以多个线程间的通信是一个线程的数据可以直接提供给其他线程使用，而不必通过操作系统（也就是内核的调度）。
#### 1.锁机制
包括`互斥锁、条件变量、读写锁`；
互斥锁提供了以排他方式防止数据结构被并发修改的方法。
使用条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
#### 2.信号量机制(Semaphore)
包括无名线程信号量和命名线程信号量
#### 3.信号机制(Signal)
类似进程间的信号处理
线程间的通信目的主要是用于线程同步。所以线程没有像进程通信中的用于数据交换的通信机制。

### linux中进程间通信和线程间通信的区别
1.linux中的进程，是有fork()系统调用创建的，进程间都有`独立的地址空间`，他们之间不能直接通信，必须通过一些IPC进程进程间通信机制来完成。
常见的IPC有：PIPE，命名管道，信号，共享内存以及socket等；
2.linux中的线程，是clone()系统调用创建的,一个进程下的线程间是共享内存空间的，故线程A可以之间访问线程B中定义的变量，但是必须注意并发的情况；
3.另：“线程上下文”的规模要远远小于进程上下文

### 进程/线程间同步机制
1.临界区  2.互斥量 3.信号量 4.事件 

### 线程或进程五种状态
新建状态、就绪状态、运行状态、阻塞状态及死亡状态。

- 创建状态(new)：进程正在被创建，`仅仅在堆上分配内存`，尚未进入就绪状态；
- 就绪状态(Runnable)：进程已处于准备运行的状态，即进程已获得除了CPU之外的所需资源，一旦分配到CPU时间片即可进入运行状态。
- 运行状态(Running)：进程正在运行，`占用CPU资源`，执行代码。任意时刻点，处于运行状态的进程(线程)的总数，不会超过是CPU的总核数；
- 阻塞状态(Blocked): `进程处于等待某一事件而放弃CPU`，暂停运行。阻塞状态分3类：
      阻塞在对象等待池：当进程在运行时执行Object.wait()方法，虚拟机会把线程放入等待池；
      阻塞在对象锁池 ：当进程在运行时企图获取已经被其他进程占用的同步锁时，虚拟机会把线程放入锁池；
      其他阻塞状态 ：当进程在运行时执行Sleep()方法，或调用其他进程的join()方法，或者发出I/O请求时，进入该阻塞状态。
- 死亡状态(dead)：进程正在被结束，这可能是进程正常结束或其他原因中断退出运行。
      进程结束运行前，系统必须置进程为dead态，再处理资源释放和回收等工作。

- Runnable -> Running： 就绪态的进程获得了CPU的时间片，进入运行态；
- Running -> Runnable: 运行态的进程在时间片用完后，必须出让CPU，进入就绪态；
- Running -> Blocked： 当进程请求资源的使用权(如外设)或等待事件发生(如I/O完成)时，由运行态转换为阻塞态；
- Blocked -> Runnable： 当进程已经获取所需资源的使用权或者等待事件已完成时，中断处理程序必须把相应进程的状态由阻塞态转为就绪态；



## 页面置换算法
参考[页面置换算法]
### 最佳置换（Optimal， OPT)
#### 基本思想
置换以后不再被访问，或者在将来最迟才回被访问的页面，缺页中断率最低。但是该算法需要依据以后各业的使用情况，而当一个进程还未运行完成是，
很难估计哪一个页面是以后不再使用或在最长时间以后才会用到的页面。所以`该算法是不能实现的`。但该算法仍然有意义，作为很亮其他算法优劣的一个标准。
#### 算例
采用固定分配局部置换的策略，嘉定系统为某进程在内存中分配了3个物理块，页面访问顺序为2、3、2、1、5、2、4、5、3、2、5、2。
假定系统未采用预调页策略，即未事先调入任何页面。进程运行时，一次将2、3、1三个页面调入内存，发生3次缺页中断。当第一次访问页面5时，
产生第4次缺页中断，根据OPT算法，淘汰页面1，因为它在以后不会在使用了；第5次缺页中断时，淘汰页面2，因为它在5、3、2三个页面中，
是在将来最迟才会被页面访问的页面。以此类推： 
注意：第4次中断时将最后不会访问的1剔除，将最后才访问的3放入最下面的内存块中，以后的调度过程中，
最后不会访问或最后才被访问的页面总是放在最下面的内存块中。内存块从上到下依次存放最先访问的页面。 
中断次数为6，缺页中断率为6/12*100% = 50%。
	
### 先进先出置换算法（First In First Out, FIFO)
#### 基本思想
置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。
但是该算法会淘汰经常访问的页面，不适应进程实际运行的规律，目前已经很少使用。
#### 算例
仍然以OPT算例为例子。 
中断次数为6，缺页中断率为9/12*100% = 75%。
#### Belady异常
一般来说，`分配给进程的物理块越多，运行时的缺页次数应该越少，使用FIFO时，可能存在相反情况，分配4个物理块的缺页竟然比3个物理块的缺页次数还多`！ 
例如：进程访问顺序为0、2、1、3、0、2、4、0、2、1、3、4。 
M=3时，缺页中断9次。缺页中断率9/12*100% = 75%。

### 最近最久未使用置换算法（Least Recently Used， LRU）
#### 基本思想
置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，
可能最近不会被访问。 
LRU算法普偏地适用于各种类型的程序，但是系统要时时刻刻对各页的访问历史情况加以记录和更新，开销太大，因此LRU算法必须要有硬件的支持。
#### 算例
仍然以OPT算例为例子。 
中断次数为6，缺页中断率为7/12*100% = 58.3%。
堆栈实现LRU： 
系统使用特殊的堆栈来存放内存中每一个页面的页号。每当访问一页时就调整一次，即把被访问页面的页号从栈中移出再压入栈顶。
因此，栈顶始终是最新被访问页面的页号，栈底始终是最近最久未被访问的页号。当发生缺页中断时，总是淘汰栈底页号所对应的页面。 


### 分页和分段存储管理有何区别？
(1) 页是信息的`物理单位`，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。段则是`信息的逻辑单位`，它含有一组其意义相对
 完整的信息。分段的目的是为了能更好地满足用户的需要。
(2) 页的大小固定且由系统决定；而`段的长度却不固定`，决定于用户所编写的程序。
(3) 分页的地址空间是一维的，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间是二维的，程序员在标识一个地址时，既需
给出段名，又需给出段内地址。
提出`分页管理的目的是为了提高内存空间的利用率`；提出`分段管理的目的除了可以提高内存空间的利用率`（相对分区管理而言）外，
主要是为了更好的实现`程序的共享和动态链接，方便用户编程`。


### 孤儿进程 VS 僵尸进程
孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被`init进程(进程号为1)`所收养，
并由init进程对它们完成状态收集工作。

僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符
仍然保存在系统中。这种进程称之为僵死进程。
僵尸进程联想到上次帮婧姐杀死 iPython 产生的僵尸进程，kill 父进程
僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程，所以，解决方法就是kill那个父进程，于是僵尸进程就可以被init进程接收，释放。
linux提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程
所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of 
the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。

### 有效用户和实际用户
有效用户 用于文件存取`许可权`检查
实际用户 我们实际是谁（即`执行程序的用户`）
#### 普通用户 mike 可以改密码？
setuid位是让普通用户可以以root用户的角色运行只有root帐号才能运行的程序或命令。
因此当程序设置了setid权限位时，普通用户会临时变成root权限，但实际用户任然是原来的mike。


### select poll epoll
（1）select，poll实现需要自己`不断轮询所有fd(file description 文件描述符)集合`，直到设备就绪，期间可能要睡眠和唤醒多次交替。 
而epoll其实也需要调用 `epoll_ wait不断轮询就绪链表`，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，
把就绪fd放入就绪链表中，并唤醒在 epoll_wait中进入睡眠的进程。　 
虽然都要睡眠和交替，但是`select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的 时候只要判断一下就绪链表是否为空就行了`，
这`节省了大量的CPU时间`，这就是`回调机制`带来的性能提升。

（2）`select，poll每次调用都要把fd集合从用户态往内核态拷贝一次`，并且要把current往设备等待队列中挂一次，而`epoll只要一次拷贝，`
 而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内 部定义的等待队列），
 这也能节省不少的开销。
#### select
基本原理：
select 函数监视的文件描述符分3类，分别是`writefds、readfds、和exceptfds`。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、
可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，
来找到就绪的描述符。

- select最大的缺陷就是单个进程所打开的`FD是有一定限制`的，它由FD_SETSIZE设置，默认值是1024。

- 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.
对socket进行扫描时是`线性扫描，即采用轮询的方法，效率较低`。

- 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，`不管哪个Socket是活跃的，都遍历一遍`。这会`浪费很多CPU时间`。
如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。
需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。

#### poll
基本原理：
- poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入
一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。
`它没有最大连接数的限制`，原因是它是`基于链表来存储`的，但是同样有一个缺点：
- 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
- poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

#### epoll
epoll使用`一个文件描述符管理多个描述符`，将用户关系的文件描述符的事件存放到内核的一个`事件表`中，这样在用户空间和内核空间的copy只需一次。
基本原理：
epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，
epoll使用`“事件”的就绪通知方式`，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的`回调机制`来激活该fd，epoll_wait便可以收到通知。
虽然连接数有上限，但是很大
epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，`而是一个代表就绪描述符
数量的值`，你只需要去`epoll指定的一个数组中依次取得相应数量的文件描述符即可`，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。

另一个本质的改进在于`epoll采用基于事件的就绪通知方式`。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，
而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时`，内核会采用类似callback的回调机制，迅速激活这个文件描述符`，
当进程调用epoll_wait()时便得到通知。

##### LT(level trigger 水平触发) 和 ET(edge trigger 边缘触发)
- LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序可以不立即处理该事件`。下次调用epoll_wait时，
会`再次响应应用程序并通知此事件`。
- ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须`立即处理该事件`。如果不处理，下次调用epoll_wait时，
`不会再次响应应用程序并通知此事件`。
边缘触发比水平触发更高效的原因：`不会让同一个文件描述符多次被处理,比如有些文件描述符已经不需要再读写了,但是在水平触发下每次都会返回,
而边缘触发只会返回一次。`
最后提醒一点,如果设置边缘触发,则必须将对应的文件描述符设置为非阻塞模式并且循环读取数据。否则会导致程序的效率大大下降。 
poll和epoll默认采用的都是水平触发,只是epoll可以修改成边缘触发。



##### epoll优点
1）支持`一个进程打开大数目的socket描述符(FD)`
2）`IO效率不随FD数目增加而线性下降` 
3）使用`mmap`加速内核与用户空间的消息传递。

最后总结一下,epoll比select和poll高效的原因主要有两点： 
1. 减少了用户态和内核态之间的文件描述符拷贝 
2. 减少了对就绪文件描述符的遍历

### 命令
#### top命令
top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。
#### 查看cpu信息
cat /proc/cpuinfo
cat /proc/meminfo
#### 查看硬盘信息
df -lh
#### 更常用的命令(显示系统核心版本号、名称、机器类型等)
uname -a
#### netstat ：显示网络状态
Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。
#### tcpdump
tcpdump：主要是截获通过本机网络接口的数据，用以分析。能够截获当前所有通过本机网卡的数据包。它拥有灵活的过滤机制，可以确保得到想要的数据。
#### ipcs：检查系统上共享内存的分配
ipcs是Linux下显示进程间通信设施状态的工具。可以显示消息队列、共享内存和信号量的信息。对于程序员可能更有用些，普通的系统管理员一般用不到此指令。



### fd 文件描述符
fd只是一个整数，在open时产生。起到一个索引的作用，进程通过PCB中的文件描述符表找到该fd所指向的文件指针filp。
文件描述符的操作(如: open)返回的是一个文件描述符,内核会在每个进程空间中维护一个文件描述符表, 所有打开的文件都将通过此表中的文件描述符来引用; 
而流(如: fopen)返回的是一个FILE结构指针, FILE结构是包含有文件描述符的，FILE结构函数可以看作是对fd直接操作的系统调用的封装, 它的优点是带有I/O缓存
每个进程在PCB（Process Control Block）即进程控制块中都保存着一份文件描述符表，文件描述符就是这个表的索引，文件描述表中每个表项都有一个指向已打开文件的指针


### 如何定位内存泄露？
内存泄漏是指堆内存的泄漏。堆内存是指程序从堆中分配的、大小任意的（内存块的大小可以在程序运行期决定）、使用完后必须显示释放的内存。
只能使用top指令观察进程的动态内存总额。
使用Linux命令回收内存，可以使用ps、kill两个命令检测内存使用情况和进行回收。



#### 静态链接与动态链接：
- 静态链接方法：#pragma comment(lib, "test.lib") ，静态链接的时候，`载入代码就会把程序会用到的动态代码或动态代码的地址确定下来`
静态库的链接可以使用静态链接，动态链接库也可以使用这种方法链接导入库
- 动态链接方法：LoadLibrary()/GetProcessAddress()和FreeLibrary()，使用这种方式的程序并不在一开始就完成动态链接，
而是`直到真正调用动态库代码时，载入程序才计算(被调用的那部分)动态代码的逻辑地址，然后等到某个时候`，程序又需要调用另外某块动态代码时，
载入程序又去计算这部分代码的逻辑地址，所以，这种方式使程序初始化时间较短，但运行期间的性能比不上静态链接的程序。
`一些库函数的链接载入推迟到程序运行的时期（runtime`）。这就是如雷贯耳的动态链接库（dynamic link library）技术。
- 动态链接是指在生成可执行文件时不将所有程序用到的函数链接到一个文件，因为有许多函数在操作系统带的dll文件中，当程序运行时直接从操作
系统中找。 而静态链接就是把所有用到的函数全部链接到exe文件中。
- 动态链接是只建立一个引用的接口，而真正的代码和数据存放在另外的可执行模块中，在运行时再装入；而静态链接是把所有的代码和数据都复制到
本模块中，运行时就不再需要库了。





[页面置换算法]:http://blog.csdn.net/u011080472/article/details/51206332