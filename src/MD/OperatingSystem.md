# 操作系统相关知识

### 自旋锁（SpinLock）
有种 try_lock 的赶脚
自旋锁是专为防止多处理器并发而引入的一种锁。如果是单核处理器，则自旋锁定义为空操作，因为简单的关闭中断即可实现互斥。
自旋锁最多只能被一个线程持有，如果一个线程试图请求一个已被争用(已被另一个线程持有)的自旋锁，那么等待自旋锁的线程将会
`反复检查自旋锁是否释放`，不会进入睡眠状态，一直处于`忙等待状态(busy-waiting)`，直到获取该自旋锁才能继续执行未完成的任务，
所以常用于短期保护某段代码。
另外，持有自旋锁的进程也不允许睡眠，不然会造成死锁——因为睡眠可能造成持有锁的进程被重新调度，而再次申请自己已持有的锁。
 
事实上，自旋锁的初衷就是：`在短期间内进行轻量级的锁定`。一个被争用的自旋锁使得请求它的线程在等待锁重新可用的期间进行自旋(特别浪费处理器时间)，所以自旋锁不应该被持有时间过长。如果需要长时间锁定的话, 最好使用信号量。
 
自旋锁的基本形式如下：
```
spin_lock(&mr_lock);
//临界区
spin_unlock(&mr_lock);
```
同一时刻只有一个线程允许处于临界区中，可用来防止多处理器中并发访问临界区，抢占共享资源造成的竞争。

### 信号量(Semaphore)
信号量是一种机制。在进入一个关键代码段之前，线程必须获取一个信号量；一旦执行完该关键代码段，则释放获取的信号量。
如果获取不到信号量，则进入等待队列，并保持休眠状态(sleep-waiting)，此时，`线程释放占用的处理器`，以便处理器执行其它任务。
当有未被持有的信号量时，唤醒队列中的线程，线程从而获取信号量，继续执行未完成的任务。
`p操作（wait）`：申请一个单位资源，进程进入
`v操作（signal）`：释放一个单位资源，进程出来

### 互斥量（Mutex）
同临界区有些类似，只有拥有互斥对象(即互斥量)的线程才具有访问共享资源的权限，由于互斥对象只有一个，因此就决定了任何情况下此共享资源都不会同时被多个线程所访问。
当占据资源的线程在任务处理完任务后应释放占有的的互斥对象，以便其他线程在获得该互斥对象后得以访问资源。

### 信号量与互斥量
#### 互斥量与信号量的区别？
 (1) 互斥量用于`线程的互斥`，信号量用于`线程的同步`
这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别
 
互斥：是指某一资源同时`只允许一个访问者对其进行访问`，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的
 
同步：是指在互斥的基础上（大多数情况），通过其它机制`实现访问者对资源的有序访问`。在大多数情况下，`同步已经实现了互斥`，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
 
(2) 互斥量值只能为0/1，信号量值可以为非负整数
也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问

(3) 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到

### 临界区（Critical Section）
在任意时刻只允许一个线程对共享资源进行访问。如果有多个线程试图同时访问同一临界区，那么在有一个线程进入后其他所有试图访问此临界区的
线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的。

### 死锁
是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去,陷入死循环。
假设有一个或多个内核任务和一个或多个资源，每个内核都在等待其中的一个资源，但所有的资源都已经被占用了，也就是说。这便会发生所有内核任
务都在相互等待，但它们永远不会释放已经占有的资源，于是任何内核任务都无法获得所需要的资源，无法继续运行，这便意味着死锁发生了。自死琐
是说自己占有了某个资源，然后自己又申请自己已占有的资源，显然不可能再获得该资源，因此就自缚手脚了。

#### 死锁的四个必要条件
`（1）互斥条件`：一个资源每次只能被一个进程使用。  
`（2）请求与保持条件`：一个进程因请求资源而阻塞时，对已获得的资源保持不放。  
`（3）不剥夺条件`:进程已获得的资源，在末使用完之前，不能强行剥夺。  
`（4）循环等待条件`:若干进程之间形成一种头尾相接的循环等待资源关系。

#### 解决死锁的策略
`(1) 死锁预防`：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，
这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。
`(2) 死锁避免`：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用银行家算法。死锁避免算法的执行会增加系统的开销。
`(3) 死锁检测`：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。
`(4) 死锁解除`：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。

### 进程和线程的区别？
进程和线程的主要差别在于它们是不同的操作系统资源管理方式。`进程有独立的地址空间，`一个进程崩溃后，在保护模式下不会对其它进程产生影响，
而线程只是一个进程中的不同执行路径。`线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉`，
所以多进程的程序要比多线程的程序健壮，但在`进程切换时，耗费资源较大`，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，
只能用线程，不能用进程。
定义方面：进程是程序在某个数据集合上的一次运行活动；线程是进程中的一个执行路径。
角色方面：在支持线程机制的系统中，`进程是系统资源分配的单位`，`线程是系统调度的单位`。
资源共享方面：进程之间不能共享资源，而线程共享所在进程的地址空间和其它资源。同时`线程还有自己的栈和栈指针，程序计数器等寄存器`。
独立性方面：`进程有自己独立的地址空间，而线程没有，线程必须依赖于进程而存在`。
1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.
2) 线程的划分尺度小于进程，使得`多线程程序的并发性高。`
3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。
4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。

## 通信
### 进程间通信
进程的通信机制主要有：管道、有名管道、消息队列、信号量、共享空间、信号、套接字。
#### 1.信号
信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程
不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。信号是进程间通信机制中唯一的异步通信机制，可以看作是异步
通知，通知接收信号的进程有哪些事情发生了。信号机制经过POSIX实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。信号事
件的发生有两个来源：硬件来源(比如我们按下了键盘或者其它硬件故障)；软件来源。
信号分为可靠信号和不可靠信号，实时信号和非实时信号。
进程有三种方式响应信号：忽略信号 捕捉信号 执行缺省操作
#### 2.信号量
信号量也可以说是一个计数器，常用来处理进程或线程同步的问题，特别是对临界资源的访问同步问题。临界资源：为某一时刻只能由一个进程或线程
操作的资源，当信号量的值大于或等于0时，表示可以供并发进程访问的临界资源数，当小于0时，表示正在等待使用临界资源的进程数。更重要的是，
信号量的值仅能由PV操作来改变。
#### 3.消息队列
消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符标识，于管道不同的是，消息队列存放在内核中，只有在内核重启时才能删除一
个消息队列，内核重启也就是系统重启，同样消息队列的大小也是受限制的。
#### 4.共享内存
共享内存就是分配一块能被其他进程访问的内存。共享内存可以说是最有用的进程间通信方式，也是`最快的IPC`形式。首先说下在使用共享内存区前，
必须通过系统函数将其附加到进程的地址空间或说为映射到进程空间。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到 进程A、B各自
的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。
对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而 共享内存则只拷贝两次数据[1]：一次从输入文件到共享内存区，
另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就 解除映射，有新的通信时，再重新建立共享内存区域。
而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存 中的内容往往是在解除映射时才写回文件的。
因此，采用共享内存的通信方式效率是非常高的。
#### 5.管道
管道传递数据是单向性的，只能从一方流向另一方，也就是一种半双工的通信方式；只用于有亲缘关系的进程间的通信，亲缘关系也就是父子进程或
兄弟进程；没有名字并且大小受限，传输的是无格式的流，所以两进程通信时必须约定好数据通信的格式。管道它就像一个特殊的文件，但这个文件之
存在于内存中，在创建管道时，系统为管道分配了一个页面作为数据缓冲区，进程对这个数据缓冲区进行读写，以此来完成通信。其中一个进程只能读
一个只能写，所以叫半双工通信，为什么一个只能读一个只能写呢?因为写进程是在缓冲区的末尾写入，读进程是在缓冲区的头部读取，他们各自的数
据结构不同，所以功能不同。
#### 6.命名管道
命名管道(NamedPipe)是服务器进程和一个或多个客户进程之间通信的单向或双向管道。不同于匿名管道的是：命名管道可以在不相关的进程之间和不
同计算机之间使用，服务器建立命名管道时给它指定一个名字，任何进程都可以通过该名字打开管道的另一端，根据给定的权限和服务器进程通信。
命名管道提供了相对简单的编程接口，使通过网络传输数据并不比同一计算机上两进程之间通信更困难，不过如果要同时和多个进程通信它就力不从心了。
命名管道不同与管道只能在具有亲缘关系的进程间通信了。它提供了一个路径名与之关联，有了自己的传输格式。
命名管道和管道的不同之处还有一点是,有名管道是个设备文件，存储在文件系统中，没有亲缘关系的进程也可以访问，但是它要按照先进先出的原则
读取数据。同样也是单双工的。
#### 7.套接字
套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机间的进程通信。

### 线程间通信
线程间通信：由于多线程共享地址空间和数据空间，所以多个线程间的通信是一个线程的数据可以直接提供给其他线程使用，而不必通过操作系统（也就是内核的调度）。
#### 1.锁机制
包括`互斥锁、条件变量、读写锁`；
互斥锁提供了以排他方式防止数据结构被并发修改的方法。
使用条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
#### 2.信号量机制(Semaphore)
包括无名线程信号量和命名线程信号量
#### 3.信号机制(Signal)
类似进程间的信号处理
线程间的通信目的主要是用于线程同步。所以线程没有像进程通信中的用于数据交换的通信机制。

### linux中进程间通信和线程间通信的区别
1.linux中的进程，是有fork()系统调用创建的，进程间都有`独立的地址空间`，他们之间不能直接通信，必须通过一些IPC进程进程间通信机制来完成。
常见的IPC有：PIPE，命名管道，信号，共享内存以及socket等；
2.linux中的线程，是clone()系统调用创建的,一个进程下的线程间是共享内存空间的，故线程A可以之间访问线程B中定义的变量，但是必须注意并发的情况；
3.另：“线程上下文”的规模要远远小于进程上下文

### 进程/线程间同步机制
1.临界区  2.互斥量 3.信号量 4.事件 

### 线程或进程五种状态
新建状态、就绪状态、运行状态、阻塞状态及死亡状态。

- 创建状态(new)：进程正在被创建，`仅仅在堆上分配内存`，尚未进入就绪状态；
- 就绪状态(Runnable)：进程已处于准备运行的状态，即进程已获得除了CPU之外的所需资源，一旦分配到CPU时间片即可进入运行状态。
- 运行状态(Running)：进程正在运行，`占用CPU资源`，执行代码。任意时刻点，处于运行状态的进程(线程)的总数，不会超过是CPU的总核数；
- 阻塞状态(Blocked): `进程处于等待某一事件而放弃CPU`，暂停运行。阻塞状态分3类：
      阻塞在对象等待池：当进程在运行时执行Object.wait()方法，虚拟机会把线程放入等待池；
      阻塞在对象锁池 ：当进程在运行时企图获取已经被其他进程占用的同步锁时，虚拟机会把线程放入锁池；
      其他阻塞状态 ：当进程在运行时执行Sleep()方法，或调用其他进程的join()方法，或者发出I/O请求时，进入该阻塞状态。
- 死亡状态(dead)：进程正在被结束，这可能是进程正常结束或其他原因中断退出运行。
      进程结束运行前，系统必须置进程为dead态，再处理资源释放和回收等工作。

- Runnable -> Running： 就绪态的进程获得了CPU的时间片，进入运行态；
- Running -> Runnable: 运行态的进程在时间片用完后，必须出让CPU，进入就绪态；
- Running -> Blocked： 当进程请求资源的使用权(如外设)或等待事件发生(如I/O完成)时，由运行态转换为阻塞态；
- Blocked -> Runnable： 当进程已经获取所需资源的使用权或者等待事件已完成时，中断处理程序必须把相应进程的状态由阻塞态转为就绪态；



## 页面置换算法
参考[页面置换算法]
### 最佳置换（Optimal， OPT)
#### 基本思想
置换以后不再被访问，或者在将来最迟才回被访问的页面，缺页中断率最低。但是该算法需要依据以后各业的使用情况，而当一个进程还未运行完成是，
很难估计哪一个页面是以后不再使用或在最长时间以后才会用到的页面。所以`该算法是不能实现的`。但该算法仍然有意义，作为很亮其他算法优劣的一个标准。
#### 算例
采用固定分配局部置换的策略，嘉定系统为某进程在内存中分配了3个物理块，页面访问顺序为2、3、2、1、5、2、4、5、3、2、5、2。
假定系统未采用预调页策略，即未事先调入任何页面。进程运行时，一次将2、3、1三个页面调入内存，发生3次缺页中断。当第一次访问页面5时，
产生第4次缺页中断，根据OPT算法，淘汰页面1，因为它在以后不会在使用了；第5次缺页中断时，淘汰页面2，因为它在5、3、2三个页面中，
是在将来最迟才会被页面访问的页面。以此类推： 
注意：第4次中断时将最后不会访问的1剔除，将最后才访问的3放入最下面的内存块中，以后的调度过程中，
最后不会访问或最后才被访问的页面总是放在最下面的内存块中。内存块从上到下依次存放最先访问的页面。 
中断次数为6，缺页中断率为6/12*100% = 50%。
	
### 先进先出置换算法（First In First Out, FIFO)
#### 基本思想
置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。
但是该算法会淘汰经常访问的页面，不适应进程实际运行的规律，目前已经很少使用。
#### 算例
仍然以OPT算例为例子。 
中断次数为6，缺页中断率为9/12*100% = 75%。
#### Belady异常
一般来说，`分配给进程的物理块越多，运行时的缺页次数应该越少，使用FIFO时，可能存在相反情况，分配4个物理块的缺页竟然比3个物理块的缺页次数还多`！ 
例如：进程访问顺序为0、2、1、3、0、2、4、0、2、1、3、4。 
M=3时，缺页中断9次。缺页中断率9/12*100% = 75%。

### 最近最久未使用置换算法（Least Recently Used， LRU）
#### 基本思想
置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，
可能最近不会被访问。 
LRU算法普偏地适用于各种类型的程序，但是系统要时时刻刻对各页的访问历史情况加以记录和更新，开销太大，因此LRU算法必须要有硬件的支持。
#### 算例
仍然以OPT算例为例子。 
中断次数为6，缺页中断率为7/12*100% = 58.3%。
堆栈实现LRU： 
系统使用特殊的堆栈来存放内存中每一个页面的页号。每当访问一页时就调整一次，即把被访问页面的页号从栈中移出再压入栈顶。
因此，栈顶始终是最新被访问页面的页号，栈底始终是最近最久未被访问的页号。当发生缺页中断时，总是淘汰栈底页号所对应的页面。 


### 分页和分段存储管理有何区别？
(1) 页是信息的`物理单位`，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。段则是`信息的逻辑单位`，它含有一组其意义相对
 完整的信息。分段的目的是为了能更好地满足用户的需要。
(2) 页的大小固定且由系统决定；而`段的长度却不固定`，决定于用户所编写的程序。
(3) 分页的地址空间是一维的，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间是二维的，程序员在标识一个地址时，既需
给出段名，又需给出段内地址。
提出`分页管理的目的是为了提高内存空间的利用率`；提出`分段管理的目的除了可以提高内存空间的利用率`（相对分区管理而言）外，
主要是为了更好的实现`程序的共享和动态链接，方便用户编程`。


### 孤儿进程 VS 僵尸进程
孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被`init进程(进程号为1)`所收养，
并由init进程对它们完成状态收集工作。

僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符
仍然保存在系统中。这种进程称之为僵死进程。
僵尸进程联想到上次帮婧姐杀死 iPython 产生的僵尸进程，kill 父进程
僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程，所以，解决方法就是kill那个父进程，于是僵尸进程就可以被init进程接收，释放。
linux提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程
所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of 
the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。

### 有效用户和实际用户
有效用户 用于文件存取`许可权`检查
实际用户 我们实际是谁（即`执行程序的用户`）
#### 普通用户 mike 可以改密码？
setuid位是让普通用户可以以root用户的角色运行只有root帐号才能运行的程序或命令。
因此当程序设置了setid权限位时，普通用户会临时变成root权限，但实际用户任然是原来的mike。


### select poll epoll
（1）select，poll实现需要自己`不断轮询所有fd(file description 文件描述符)集合`，直到设备就绪，期间可能要睡眠和唤醒多次交替。 
而epoll其实也需要调用 `epoll_ wait不断轮询就绪链表`，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，
把就绪fd放入就绪链表中，并唤醒在 epoll_wait中进入睡眠的进程。　 
虽然都要睡眠和交替，但是`select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的 时候只要判断一下就绪链表是否为空就行了`，
这`节省了大量的CPU时间`，这就是`回调机制`带来的性能提升。

（2）`select，poll每次调用都要把fd集合从用户态往内核态拷贝一次`，并且要把current往设备等待队列中挂一次，而`epoll只要一次拷贝，`
 而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内 部定义的等待队列），
 这也能节省不少的开销。
#### select
基本原理：
select 函数监视的文件描述符分3类，分别是`writefds、readfds、和exceptfds`。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、
可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，
来找到就绪的描述符。

- select最大的缺陷就是单个进程所打开的`FD是有一定限制`的，它由FD_SETSIZE设置，默认值是1024。

- 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.
对socket进行扫描时是`线性扫描，即采用轮询的方法，效率较低`。

- 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，`不管哪个Socket是活跃的，都遍历一遍`。这会`浪费很多CPU时间`。
如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。
需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。

#### poll
基本原理：
- poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入
一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。
`它没有最大连接数的限制`，原因是它是`基于链表来存储`的，但是同样有一个缺点：
- 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。
- poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

#### epoll
epoll使用`一个文件描述符管理多个描述符`，将用户关系的文件描述符的事件存放到内核的一个`事件表`中，这样在用户空间和内核空间的copy只需一次。
基本原理：
epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，
epoll使用`“事件”的就绪通知方式`，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的`回调机制`来激活该fd，epoll_wait便可以收到通知。

##### LT(level trigger 水平触发) 和 ET(edge trigger 边缘触发)
- LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序可以不立即处理该事件`。下次调用epoll_wait时，
会`再次响应应用程序并通知此事件`。
- ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须`立即处理该事件`。如果不处理，下次调用epoll_wait时，
`不会再次响应应用程序并通知此事件`。
边缘触发比水平触发更高效的原因：`不会让同一个文件描述符多次被处理,比如有些文件描述符已经不需要再读写了,但是在水平触发下每次都会返回,
而边缘触发只会返回一次。`
最后提醒一点,如果设置边缘触发,则必须将对应的文件描述符设置为非阻塞模式并且循环读取数据。否则会导致程序的效率大大下降。 
poll和epoll默认采用的都是水平触发,只是epoll可以修改成边缘触发。

##### epoll优点
1）支持`一个进程打开大数目的socket描述符(FD)`
2）`IO效率不随FD数目增加而线性下降` 
3）使用`mmap`加速内核与用户空间的消息传递。

最后总结一下,epoll比select和poll高效的原因主要有两点： 
1. 减少了用户态和内核态之间的文件描述符拷贝 
2. 减少了对就绪文件描述符的遍历


##### top命令
top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。




[页面置换算法]:http://blog.csdn.net/u011080472/article/details/51206332