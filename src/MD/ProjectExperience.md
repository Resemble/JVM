## 项目经历

#### 项目需要改进的地方
- 爬虫，更新的时候更新10条，如果可以做的话可以改成爬一条，进行数据库匹配然后再爬
- 邮件服务，多个ip发送邮件
- 爬虫批量插入，我用的是拼成一条sql查完，可以改成500条一批插入



#### 优化地方有
- 邮件服务，多线程，异步，多个账户，原生java(验证 session transport)
- 可乐后端报表服务，数据库连接池，加入请求超时(占用资源) 从jmeter测试500个请求tomcat宕机到1000个请求没有任何问题
- 我们的 api-gate 网关api还没有完全实现
- 使用docker 部署 centOs7(200m) 易维护，不干扰主机
- redis是作为一个模块放入，可以改成一个cache-api微服务
- 数据分区，分表

### 设计模式
模板方法，定义了一个baseReport抽象类，然后延迟到子类实现具体获取
单例模式，创建一个redis实例时用了单例模式，只要一个循环使用节约cpu资源

#### 抽象类和普通类的继承
`抽象类更像是提供一种模板`。。
抽象方法必须被子类实现,没有方法体。
抽象类的作用是普通类无法替代的，抽象类的作用主要是提供一种模版

抽象方法：在类中没有方法体的方法，就是抽象方法。
抽象类：含有抽象方法的类就叫抽象类。
抽象类中的抽象方法必须被实现！
如果一个子类没有实现父类中的抽象方法，则子类也成为了一个抽象类！
抽象类中的普通方法，可以不必实现。

```java
// 抽象类
abstract class Person {
public abstract void f();
}
// 普通类
class Person {
public void f() {
System.out.println("父类");
}
}
```


我专门来到牛客看了看大神在面试的时候怎么你回答的，自己是怎么回答的。结果就发现了问题。大神们的回答，不论是项目还是问题，都回答的很
有条理，`而且分析到问题的里，里面了`，而我只是 把概念说了一下，根本没有说到问题的实质，直到这个时候我才了解到为什么搜狗的面试官对我的
评价时呢样的。

#### 如果一句话来谈SOA和微服务的区别
即微服务不再强调传统SOA架构里面比较重的ESB企业服务总线，同时SOA的思想进入到单个业务系统内部实现真正的组件化。

   SOA实现	                                      微服务架构实现
企业级，自顶向下开展实施	                     团队级，自底向上开展实施
服务由多个子系统组成，粒度大	                 一个系统被拆分成多个服务，粒度细
企业服务总线，集中式的服务架构	                 无集中式总线，松散的服务架构
集成方式复杂（ESB/WS/SOAP）	                 集成方式简单（HTTP/REST/JSON）
单块架构系统，相互依赖，部署复杂	             服务都能独立部署


### 微服务的思想  
小，独立进程，自动化
- 微服务架构即是采用一组`小服务来构建应用的方法`。
- `每个服务运行在独立的进程中`，不同服务通过一些`轻量级交互机制来通信`， 例如 RPC、HTTP 等。
- 服务围绕业务能力来构建，并依赖自动部署机制来独立部署。

微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可`被独立部署，`各个微服务之间是松耦合的。
每个微服务仅关注于`完成一件任务并很好地完成该任务`。在所有情况下，每个任务代表着一个小的业务能力。


### 服务注册 服务发现
服务发现的关键是服务注册表，`服务注册表是可用服务实例的数据库，它提供了管理和查询使用的API`。服务实例使用这些管理API进行服务的注册和注销，
系统组件使用查询API来发现可用的服务实例。
有两种服务发现的模式：客户端发现和服务端发现。在使用客户端发现模式的系统中，`客户端直接查询服务注册表，选择一个可用的实例并发起请求`，
在一个使用服务端发现模式的系统中，`客户端通过路由发起请求，路由会查询服务注册表并把请求转发到可用的服务实例上`。
对服务实例来讲有两种方式可以对服务注册表进行注册和注销，一种是服务实例本身通过服务注册表来注册自己，也就是self-registration模式，
另一种则是第三方系统组件代表实例来处理服务的注册和注销，也就是third-party registration模式。
把应用拆分成为一个一个的单个服务，应用Docker技术，不依赖任何服务器和数据模型，是一个 全栈应用，可以通过自动化方式独立部署，每个服务运行在自己的进程中
- 客户端发现模式
使用客户端发现模式时，客户端决定相应服务实例的网络位置，并且对请求实现负载均衡。`客户端查询服务注册表，`后者是一个可用服务实例的数据库；然后使用负
载均衡算法从中选择一个实例，并发出请求。客户端从服务注册服务中查询，其中是所有可用服务实例的库。`客户端使用负载均衡算法从多个服务实例中选择出一
个，然后发出请求。`
第一步首先是访问服务注册库（更多是API GateWay提供的一个能力）返回一个已经动态均衡后的服务可用地址，第二步即客户端和该地址直接建立连接进行服务消费和访问。
在这种模式的实现中有两个重点，其一是动态负载均衡算法，其二是服务网关需要能够对原始服务提供点进行实时的心跳检测以确定服务提供的可用性。
缺点：底层的IP虽然动态提供出去了，但是最终仍然暴露给了服务消费方，再需要进一步做安全和防火墙隔离的场景下显然是不能满足要求的。
- 服务端发现模式
`客户端通过负载均衡器向某个服务提出请求，负载均衡器查询服务注册表`，并将请求转发到可用的服务实例。如同客户端发现，服务实例在服务注册表中注册或注销。在原文中有图示，基本看图就清楚了，即在服务注册库前新增加了一个Load
Balancer节点。注：这两个节点感觉是可以合并到API GateWay的能力中去的。
服务端发现模式兼具优缺点。它最大的优点是客户端无需关注发现的细节，只需要简单地向负载均衡器发送请求，这减少了编程语言框架需要完成的发现逻辑。并且
如上文所述，某些部署环境免费提供这一功能。这种模式也有缺点。除非负载均衡器由部署环境提供，否则会成为一个需要配置和管理的高可用系统组件。

- 自注册模式
当使用自注册模式时，微服务实例本身需要负责在服务注册表中注册和卸载，并且需要发送心跳来保证注册信息不会过时。
- 第三方注册模式
采用第三方注册模式时，服务实例并不负责向服务注册表注册，而是由另外一个系统模块即服务管理器（另称服务注册中心）负责注册。服务管理器
通过查询部署环境或订阅事件来跟踪运行服务的改变。当管理器发现一个新可用服务，会向注册表注册此服务。同时，服务管理器也负责卸载终止的服务实例

### 两个项目之间如何通信
两个Java项目，他们之间进行信息的通信
前提：必须知道要通信的java项目（接收请求方）的`服务器的IP地址和访问路径`。
其实两个java项目之间的通信还是使用HTTP的请求。主要有两种方式：
①使用`apache的HttpClient`方式。
②使用JDK自带的`java.NET包下的HttpURLConnection`方式。

### 邮件服务
整个工程采用微服务架构，application 层分为2个服务，一个是我们的外包可乐报表服务，
可乐全国各地的装瓶厂的销量进行分析整理展示，一个是公司自己的项目 jupiter，将别的商家的
用户购买情况进行分析，进行用户特征提取，建模，进行个性化营销。common层 api gateway,
,身份验证token，服务器权限拦截器， 流控，路由，黑白名单，user-api用户管理，用户权限 修改密码。
data-platform 可乐报表数据处理和jupiter的数据处理最开始采用clojure，最后转成spark.
email-api 邮件服务，发送邮件。

#### 搭建邮件服务器
免费的不好用,或者收费的价格太贵…那干脆自己搭建邮件服务器了.
centOs7
- 域名解析
- 接收和投递邮件 (Postfix，SMTP协议) 25
- 从邮件客户端读取邮件服务器上的邮件 (Dovecot，IMAP协议) 110

#### 难题
- 8110大端口对外开放


#### IMAP VS pop3
POP3协议允许电子邮件客户端下载服务器上的邮件，但是在客户端的操作（如移动邮件、标记已读等），不会反馈到服务器上，比如通过客户端收取了
邮箱中的3封邮件并移动到其他文件夹，邮箱服务器上的这些邮件是没有同时被移动的 。
而IMAP提供webmail 与电子邮件客户端之间的双向通信，客户端的操作都会反馈到服务器上，对邮件进行的操作，服务器上的邮件也会做相应的动作。

#### 邮件服务
- 邮件找回密码 登陆的验证码 邮件营销（一天几千封邮件） 预热
- 频率限制 批量发送(后台开线程定期扫描，记录发送状态进行跟踪，邮件是否打开（长宽为0，display none; href） 链接是否点击 ticket)
- 登陆验证码 使用异步，邮箱存入缓存 redis 中记录失败次数，次数超过10次，我认为这边出问题了。
- 异步利用 spring @Async注解，在被调用的方法上面加上@Async注解，在调用的方法加上@EnableAsync，当然就是调用和被调用不能在一个类里面，要分开
首先，方法所属的类的对象需要是被Spring容器所管理的，也就是指被@Controller @Service @Repository @Component这些注解的类。
其次，需要在Spring的配置文件中打开task注解驱动 使用 ExecutorService 启动一个线程 2种方式都尝试了，都能够满足需求
- 关于邮件登陆问题，最开始我采用是 spring 自己封装的 JavaMailSenderImpl，只需要在配置里面配置好
端口25、协议smtp、主机，但是有一个缺点，只能有一个邮箱登陆，java原生的邮件登陆，此时是通过在数据库建了一张表
包括主机 协议 端口，读表，并且将普通信息 每个邮件都有的信息 标题 发送邮箱 正文 放到一个函数，
将比如附件信息放到了另外一个函数。
- 附件需要说明的是 附件名称过长，收到的附件名称是乱码，然后我们使用腾讯邮箱发送是正常的
有一个属性是 splilongparameters，我将这个属性设置为 false 就解决了这个问题。
- 一般邮箱登陆端口是25，但是腾讯邮箱465。
// 解决附件名过长乱码问题
System.getProperties().setProperty("mail.mime.splitlongparameters", "false");


### redis docker 详细
### redis
#### 使用redis有哪些好处？
(1) `速度快`，因为数据存在`内存`中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 
(2) 支持`丰富数据类型`，支持string，list，set，sorted set，hash 
(3) 支持`事务`，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 
(4) 丰富的特性：`可用于缓存，消息，按key设置过期时间`，过期后将会自动删除
#### redis相比memcached有哪些优势？
(1) memcached所有的值均是简单的字符串，Redis作为其替代者，支持更为`丰富的数据类型` 
(2) redis的速度比memcached`快`很多 
(3) redis可以`持久化其数据`

####  Ehcache 快 简单 包比较小 轻量依赖少  扩展 监听
1. 够快
Ehcache的发行有一段时长了，经过几年的努力和不计其数的性能测试，Ehcache终被设计于large, high concurrency systems.
2. 够简单
开发者提供的接口非常简单明了，从Ehcache的搭建到运用运行仅仅需要的是你宝贵的几分钟。其实很多开发者都不知道自己用在用Ehcache，Ehcache被广泛的运用于其他的开源项目
比如：hibernate
3.够袖珍
关于这点的特性，官方给了一个很可爱的名字small foot print ，一般Ehcache的发布版本不会到2M，V 2.2.3  才 668KB。
4. 够轻量
核心程序仅仅依赖slf4j这一个包，没有之一！
5.好扩展
Ehcache提供了对大数据的内存和硬盘的存储，最近版本允许多实例、保存对象高灵活性、提供LRU(最近最少使用 Recently)、LFU(最近最不常使用 frequently)、FIFO淘汰算法，基础属性支持热配置、支持的插件多
6.监听器
缓存管理器监听器 （CacheManagerListener）和 缓存监听器（CacheEvenListener）,做一些`统计`或数据一致性广播挺好用的

#### redis
1. 支持`持久化`
     redis的本地持久化支持两种方式：RDB和AOF。RDB 在redis.conf配置文件里配置持久化触发器，AOF指的是redis没增加一条记录都会保存到持久化文件中（保存的是这条记录的生成命令），如果不是用redis做DB用的话还会不要开AOF ，数据太庞大了，重启恢复的时候是一个巨大的工程！
2.丰富的`数据类型`
    redis 支持 String 、Lists、sets、sorted sets、hashes 多种数据类型,新浪微博会使用redis做nosql主要也是它具有这些类型，时间排序、职能排序、我的微博、发给我的这些功能List 和 sorted set
   的强大操作功能息息相关
3.`高性能`
   这点跟memcache很想象，`内存`操作的级别是毫秒级的比硬盘操作秒级操作自然高效不少，较少了磁头寻道、数据读取、页面交换这些高开销的操作！这也是NOSQL冒出来的原因吧，应该是高性能
  是基于RDBMS的衍生产品，虽然RDBMS也具有缓存结构，但是始终在app层面不是我们想要的那么操控的。
4.replication
    redis提供主从复制方案，跟mysql一样增量复制而且复制的实现都很相似，这个复制跟AOF有点类似复制的是新增记录命令，主库新增记录将新增脚本发送给从库，从库根据脚本生成记录，这个过程非常快，就看网络了，一般主从都是在同一个局域网，所以可以说redis的主从近似及时同步，同事它还支持一主多从，动态添加从库，从库数量没有限制。 主从库搭建，我觉得还是采用网状模式，如果使用链式（master-slave-slave-slave-slave·····）如果第一个slave出现宕机重启，首先从master 接收 数据恢复脚本，这个是阻塞的，如果主库数据几TB的情况恢复过程得花上一段时间，在这个过程中其他的slave就无法和主库同步了。
5.`更新快`
   这点好像从我接触到redis到目前为止 已经发了大版本就4个，小版本没算过。redis作者是个非常积极的人，无论是邮件提问还是论坛发帖，他都能及时耐心的为你解答，维护度很高。有人维护的话，让我们用的也省心和放心。

##### redis 分布式锁
使用redis的setNX命令实现分布式锁　　SETNX 是『`SET if Not exists`』(如果不存在，则 SET)的简写
1、实现的原理
　　Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系。redis的SETNX命令可以方便的实现分布式锁。
1）setNX（SET if Not eXists）
将 key 的值设为 value ，当且仅当 key 不存在。
若给定的 key 已经存在，则 SETNX 不做任何动作。
返回值：
　　设置成功，返回 1 。
　　设置失败，返回 0 。
2）getSET
语法：
GETSET key value
　　将给定 key 的值`设为 value` ，并`返回` key 的旧值(`old value`)。
　　当 key 存在但不是字符串类型时，返回一个错误。
3）get
返回值：
　　当 key 不存在时，返回 nil ，否则，返回 key 的值。
　　如果 key 不是字符串类型，那么返回一个错误

### docker
#### docker和 OS 虚拟机有什么区别
##### 虚拟机：
我们传统的虚拟机需要模拟整台机器包括硬件，`每台虚拟机都需要有自己的操作系统`，虚拟机一旦被开启，`预分配给他的资源将全部被占用。`
，每一个虚拟机包括应用，必要的二进制和库，以及一个完整的用户操作系统。
##### Docker：
`容器技术是和我们的宿主机共享硬件资源`及操作系统可以实现`资源的动态分配`。
容器包含应用和其所有的依赖包，但是与其他容器`共享内核`。容器在`宿主机操作系统`中，在`用户空间以分离的``进程运行。`

虚拟机和容器都是在硬件和操作系统以上的，虚拟机有Hypervisor层，Hypervisor是`整个虚拟机的核心所在。他为虚拟机提供了虚拟的运行平台，管理虚拟机的操作系统运行`。每个虚拟机都有自己的系统和系统库以及应用。
容器没有Hypervisor这一层，并且每个容器是和宿主机共享硬件资源及操作系统，那么`由Hypervisor带来性能的损耗，在linux容器这边是不存在的`。
但是虚拟机技术也有其优势，能为应用提供一个`更加隔离的环境`，不会因为应用程序的漏洞给宿主机造成任何威胁。同时还支持跨操作系统的虚拟化，
例如你可以在linux操作系统下运行windows虚拟机。
从`虚拟化层面`来看，`传统虚拟化技术是对硬件资源的虚拟`，`容器技术则是对进程的虚拟`，从而可提供更轻量级的虚拟化，实现进程和资源的隔离。
从`架构`来看，Docker比虚拟化少了两层，取消了hypervisor层和GuestOS层，使用 `Docker Engine 进行调度和隔离`，`所有应用共用主机操作系统`，
因此在体量上，Docker较虚拟机`更轻量级`，在`性能上优`于虚拟化，接近裸机性能。从应用场景来 看，Docker和虚拟化则有各自擅长的领域，在软件开发、测试场景和生产运维场景中各有优劣
- 具体对比：
1.	docker启动快速属于`秒级别`。虚拟机通常需要`几分钟去启动`。
2.	docker需要的`资源更少`，docker在操作系统级别进行虚拟化，docker容器和内核交互，几乎没有性能损耗，性能优于通过Hypervisor层与内核层的虚拟化。；
3.	docker更`轻量`，docker的架构可以`共用一个内核与共享应用程序库，所占内存极小。`同样的硬件环境，Docker运行的镜像数远多于虚拟机数量`。对系统的利用率非常高
4.	与虚拟机相比，`docker隔离性更弱`，docker属于`进程之间的隔离`，虚拟机可实现`系统级别隔离`；
5.	安全性： `docker的安全性也更弱`。Docker的租户root和宿主机root等同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到攻击。
6.	可管理性：docker的集中化管理工具还不算成熟。各种虚拟化技术都有成熟的管理工具，例如VMware vCenter提供完备的虚拟机管理能力。
7.	`高可用和可恢复性`：docker对业务的高可用支持是通过`快速重新部署实现`的。虚拟化具备负载均衡，高可用，容错，迁移和数据保护等经过生产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%高可用，保证业务连续性。
8.	`快速创建、删除`：虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节约大量时间。
9.	`交付、部署`：虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化；Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署;


#### docker 容器间通信
- 通过端口公开（port exposure）连接
让我们运行server_img并且把该容器命名为server1，公开其80端口：
$ sudo docker run -itd --expose=80 --name=server1 server_img /bin/bash
启动该容器内的Apache HTTP服务：
$ /etc/init.d/apache2 start
- 将宿主机端口绑定（bind）至容器端口
我们可以按照以下命令来这么做：
$ sudo docker run -itd -p 8080:80 --name=server2 server_img /bin/bash
- 通过链接（link）选项去连接两个容器
sudo docker run --name=mysql_client2 `--link=mysql_server:db` -t -i kongxx/mysql_client /usr/bin/mysql -h db -u root -pletmein  
这里需要特别注意一下“–link=mysql_server:db”，这个参数就是告诉Docker容器需要使用“mysql_server”容器，并将其别名命名为db，这样在这
两个容器里就可以使用“db”来作为提供mysql数据库服务的机器名。所以在最后启动参数里我们使用的是“/usr/bin/mysql -h db -u root -pletmein”
来连接mysql数据库的。




##### Docker环境下应用开发及集群部署调试经验，熟悉主流的集群部署工具



### git 和 gitflow
#### 工作区（Working Directory）
就是你在电脑里能看到的目录，比如我的learngit文件夹就是一个工作区：
#### 版本库（Repository）
工作区有一个隐藏目录.Git，这个不算工作区，而是git的版本库。
#### 暂存区
Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。
分支和HEAD的概念我们以后再讲。
前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：
第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；
第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支

#### git reset 
git reset --mixed HEAD 将你当前的改动从缓存区中移除，但是这些改动还留在工作目录中。另一方面，如果你想完全舍弃你没有提交的改动，你可以使用 git reset --hard HEAD
--soft – 缓存区和工作目录都不会被改变
--mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响
--hard – 缓存区和工作目录都同步到你指定的提交

gitflow 有 feature 层、develop 层、release 层、master 层、hotfix 层
feature -> develop
develop -> release
release -> develop      release -> master
hotfix -> develop       hotfix -> master

           init              
git flow   feature      start
           release      finish
           hotfix       publish
                        pull
                        
git checkout hotfix



### Git VS SVN
* git有本地库
svn 的模式是：
1。写代码。3。从服务器拉回服务器的当前版本库，并解决服务器版本库与本地代码的冲突。5。将本地代码提交到服务器。
Git 分布式版本管理的模式是：
1。写代码。2。提交到本地版本库。3。从服务器拉回服务器的当前版本库，并解决服务器版本库与本地代码的冲突。
4。将远程库与本地代码合并结果提交到本地版本库。5。将本地版本库推到服务器。

* 本地提交本地提交好处主要有3点：
1) 断网提交2) 小步提交。可以对自己的阶段成果有跟踪，并且提高每次变更的安全性3) 本地库。这
个和断网提交是同一个实现，但从需求角度出发则略有不同，主要是说即使只有自己一个人开发项目，也可以轻易的让自己的代码有版本跟踪，
而不需要去费力建个什么svn server4) 本地回滚。这个其实是由于本地库的存在而产生的，但可以减少中央库上的冗余版本
* 分支策略
我可以开一个分支，做我喜欢的事
gitFlow
* tag






### 智能电影推荐
提取用户特征，对用户建模，然后推荐电影。
### scarpy
Scrapy 框架最大的特点是它的可配置性，我们在 settting 文件里面线程数 核数 * 2 + 2 线程，这样最快的，切换的时间，配置超时时间，请求 ip 数量，请求头
random user agent 防止被封，一定的请求速率，如果可以的话，可以不断换 ip 进行请求。
### bs4库(自带的库) xpath(lxml库)
BeautifulSoup BS4 进行页面解析，找到某个标签的内容，文字 链接，比较形象生动 find findAll 
Xpath 进行解析，一般需要找到一个唯一确定的 id 的节点，一层一层往下找

BeautifulSoup是一个库，而XPath是一种技术，python中最常用的XPath库是lxml
 性能 lxml >> BeautifulSoup
 易用性  BeautifulSoup >> lxml
 
### Selenium 和 PhantomJs
想要模拟下拉操作(即 js 加载的页面)，我们需要用到两个工具，一个是PhantomJs，一个是Selenium。
- Selenium是一个开源的和便携式的自动化软件测试工具，用于测试web应用程序有能力在各种浏览器和操作系统下运行。
Selenium实质上是一个`自动化测试工具`，能够`模拟用户的一些行为`操作，比如下拉网页。
- PhantomJS其实就是一个`没有界面的浏览器`，最主要的功能是能够读取js加载的页面。
其中PhantomJS同时可以换成Chrome、Firefox、Ie等等，但是PhantomJS是一个`无头的浏览器`，运行是不会跳出相应的浏览器，运行相对效率较高。
在调试中可以先换成Chrome，方便调试，最后再换成PhantomJS即可。
```
from selenium import webdriver
driver = webdriver.PhantomJS()
driver.get('网址')
```
##### 那么，怎么判断一个网站的内容是不是js动态加载的呢？
打开网易云音乐，在页面上点击右键-->View page source。会弹出一个新窗口，在新窗口中搜索你想要爬取的内容，发现`搜不到`。那就肯定是js动态加载的了。

### vueJs
使用 vueJs 的最大一个特点是 css 和 js 都是放到一个文件里面，并且渲染页面不需要刷新
 Margin:外边距
 padding:内边距
 
console.log('hello'.repeatify(3));


### 电子健康档案
电子健康档案这个项目是有用来记录人体生命特征的系统。通过用户将自己的健康信息导入系统进行管理。
这是一个实验室的项目，我负责数据库开发，负责与卫生专业人士进行交流，编
写需求文档，设计文档，统一`数据元标准`，建立一个满足国家WS卫生标准数据库



### 有什么要问我的。
公司技术栈，开源产品，公司氛围。团队协作工具，任务安排监管。


### 使用bcrypt加密


### 热部署
热部署的目的很简单，就是为了节省应用开发和发布的时间。比如，我们在使用Tomcat或者Jboss等应用服务器开发应用时，我们经常会开启热部署
功能。热部署，简单点来说，`就是我们将打包好的应用直接替换掉原有的应用，不用关闭或者重启服务器`，一切就是这么简单。

#### shell 循环
for i in `seq 10`; do command; done

### ehcache 热部署造成内存泄漏
每隔一天，服务器就会报出内存溢出
部署的时候有 this is very likely to create a memory leak，显示具体那个线程
使用 jconsole 连接发现每次删除 war 包会多一个线程
spring中的提供了一个名为org.springframework.web.util.IntrospectorCleanupListener的监听器。它主要负责  
处理由　JavaBeans  Introspector的使用而引起的缓冲泄露。spring中对它的描述如下：  
它是一个在web应用关闭的时候,清除JavaBeans Introspector的监听器.在web.xml中注册这个listener.  
可以保证在web 应用关闭的时候释放与掉这个web 应用相关的class loader 和由它管理的类  
如果你使用了JavaBeans Introspector来分析应用中的类，Introspector 缓冲中会保留这些类的引用.  
结果在你的应用关闭的时候,这些类以及web 应用相关的class loader没有被垃圾回收.  
解决办法，就是在web.xml中加入: 
```xml
<listener> 
<listener-class>org.springframework.web.util.IntrospectorCleanupListener</listener-class> 
</listener>
```
当应用需要到某个类时，则会按照下面的顺序进行类加载：
1. 使用bootstrap引导类加载器加载 JAVA_HOME/jre/lib/ext
2. 使用system系统类加载器加载 CATALINA_HOME/bin
3. webapp 应用类加载器 CATALINA_HOME/webapps
* 使用应用类加载器在WEB-INF/classes中加载
* 使用应用类加载器在WEB-INF/lib中加载
4. 使用common类加载器在CATALINA_HOME/lib中加载

##### Webapp类加载器
正如上面内容所说，Webapp类加载器，相对于传统的Java的类加载器，最主要的区别是
`子优先(child first)`
也就是说，在Web应用内，需要加载一个类的时候，不是先委托给parent，而是先自己加载，在自己的类路径上找不到才会再委托parent。
但是此处的子优先有些地方需要注意的是，Java的基础类不允许其重新加载，以及servlet-api也不允许重新加载。
那为什么要先child之后再parent呢？我们前面说是Servlet规范规定的。但确实也是实际需要。假如我们两个应用内使用了相同命名空间里的一个class，
一个使用的是Spring 2.x，一个使用的是Spring 3.x。如果是parent先加载的话，在第一个应用加载后，第二个应用再需要的时候，就直接从parent里拿到了，但是却不符合需要。
另外一点是，各个Web应用的类加载器，是相互独立的，即WebappClassloader的多个实例，只有这样，多个应用之间才可能使用不同版本的相同命令空间下的类库，而不互相受影响。
该类加载器会加载Web应用的WEB-INF/classes内的class和资源文件，以及WEB-INF/lib下的所有jar文件。
当然，有些时候，有需要还按照传统的Java类加载器加载class时，Tomcat内提供了配置，可以实现父优先。
##### Common 类加载器
通过上面的class loader组织的图，可以知道Common 类加载器，是做为webapp类加载器的parent存在的。


### 调优
数据库连接池，加入请求超时(占用资源) 从jmeter测试500个请求tomcat宕机到1000个请求没有任何问题
Http请求超时设置：如果超时设置的时间是无限长，那么当一个Http请求的线程被卡住时，这个线程所占有的资源会永远不会释放，导致内存泄漏。
连接超时
指定时间间隔（以秒计），这个时间间隔过后连接请求超时并抛出 ConnectionWaitTimeoutException。
此值指出当空闲池中没有连接可用且无法创建新连接时，连接请求等待的秒数。这通常是由于特定连接池中的连接数达到了最大值造成的。
```groovy
class test {
    def test () {
        def client = new Sql(new PGPoolingDataSource().each {
            it.url = "".toString()
            it.user = username
            it.password = password
            it.initialConnections = 5
            it.maxConnections = 20
            it.connectTimeout = 10
        })
    }
}
```
### 数据库连接池
###### 数据库连接池技术带来的优势：
1． 资源重用
由于数据库连接得到重用，避免了频繁创建、释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增进了系统运行环境的平稳性（减少内存碎片以及数据库临时进程/线程的数量）。
2． 更快的系统响应速度
数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而缩减了系统整体响应时间。
3． 新的资源分配手段
对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接的配置，实现数据库连接池技术，几年钱也许还是个新鲜话题，对于目前的业务系统而言，如果设计中还没有考虑到连接池的应用，那么…….快在设计文档中加上这部分的内容吧。某一应用最大可用数据库连接数的限制，避免某一应用独占所有数据库资源。
4． 统一的连接管理，避免数据库连接泄漏
在较为完备的数据库连接池实现中，`可根据预先的连接占用超时设定，强制收回被占用连接。从而避免了常规数据库连接操作中可能出现的资源泄漏。`


##### 数据库连接池的工作原理
连接池的工作原理主要由三部分组成，分别为连接池的建立、连接池中连接的使用管理、连接池的关闭。
第一、连接池的建立。一般在系统初始化时，连接池会根据系统配置建立，并在池中创建了几个连接对象，以便使用时能从连接池中获取。连接池中的
连接不能随意创建和关闭，这样避免了连接随意建立和关闭造成的系统开销。Java中提供了很多容器类可以方便的构建连接池，例如Vector、Stack等。
第二、连接池的管理。连接池管理策略是连接池机制的核心，连接池内连接的分配和释放对系统的性能有很大的影响。其管理策略是：
当客户请求数据库连接时，首先查看连接池中是否有空闲连接，如果存在空闲连接，则将连接分配给客户使用；如果没有空闲连接，则查看当前所开的
连接数是否已经达到最大连接数，如果没达到就重新创建一个连接给请求的客户；如果达到就按设定的最大等待时间进行等待，如果超出最大等待时间，则抛出异常给客户。
当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，如果超过就从连接池中删除该连接，否则保留为其他客户服务。
该策略保证了数据库连接的有效复用，避免频繁的建立、释放连接所带来的系统资源开销。
第三、连接池的关闭。当应用程序退出时，关闭连接池中所有的连接，释放连接池相关的资源，该过程正好与创建相反。


###### 连接池关键问题分析
1、并发问题
为了使连接管理服务具有最大的通用性，必须考虑多线程环境，即并发问题。这个问题相对比较好解决，因为Java语言自身提供了对并发管理的支 持，使用synchronized关键字即可确保线程是同步的。使用方法为直接在类方法前面加上synchronized关键字，如：
public synchronized Connection getConnection()
2、多数据库服务器和多用户
对于大型的企业级应用，常常需要同时连接不同的数据库(如连接Oracle和Sybase)。如何连接不同的数据库呢?我们采用的策略是：设计 一个符合
单例模式的连接池管理类，在连接池管理类的唯一实例被创建时读取一个资源文件，其中资源文件中存放着多个数据库的url地址()?用户名()?密 码()
等信息。如 tx.url=172.21.15.123：5000/tx_it，tx.user=yang，tx.password=yang321。根据资源文件提 供的信息，创建多个连接池类的实例，
每一个实例都是一个特定数据库的连接池。连接池管理类实例为每个连接池实例取一个名字，通过不同的名字来管理不同的连 接池。

对于同一个数据库有多个用户使用不同的名称和密码访问的情况，也可以通过资源文件处理，即在资源文件中设置多个具有相同url地址，但具有不同
用户名和密码的数据库连接信息。
3、事务处理
我们知道，事务具有原子性，此时要求对数据库的操作符合“ALL-ALL-NOTHING”原则,即对于一组SQL语句要么全做，要么全不做。
在Java语言中，Connection类本身提供了对事务的支持，可以通过设置Connection的AutoCommit属性为 false,然后显式的调用commit或rollback
方法来实现。但要高效的进行Connection复用，就必须提供相应的事务支持机制。可采用 每一个事务独占一个连接来实现，这种方法可以大大降低事务管理的复杂性。
4、连接池的分配与释放
连接池的分配与释放，对系统的性能有很大的影响。合理的分配与释放，可以提高连接的复用度，从而降低建立新连接的开销，同时还可以加快用户的访问速度。
对于连接的管理可使用空闲池。即把已经创建但尚未分配出去的连接按创建时间存放到一个空闲池中。每当用户请求一个连接时，系统首先检查空闲池内 
有没有空闲连接。如果有就把建立时间最长(通过容器的顺序存放实现)的那个连接分配给他(实际是先做连接是否有效的判断，如果可用就分配给用户，
如不可用 就把这个连接从空闲池删掉，重新检测空闲池是否还有连接);如果没有则检查当前所开连接池是否达到连接池所允许的最大连接数(maxConn),
如果没有 达到，就新建一个连接，如果已经达到，就等待一定的时间(timeout)。如果在等待的时间内有连接被释放出来就可以把这个连接分配给等待
的用户，如果 等待时间超过预定时间timeout,则返回空值(null)。系统对已经分配出去正在使用的连接只做计数，当使用完后再返还给空闲池。
对于空闲连接的状 态，可开辟专门的线程定时检测，这样会花费一定的系统开销，但可以保证较快的响应速度。也可采取不开辟专门线程，只是在分配
前检测的方法。
5、连接池的配置与维护
连接池中到底应该放置多少连接，才能使系统的性能最佳?系统可采取设置最小连接数(minConn)和最大连接数(maxConn)来控制连接 池中的连接。
最小连接数是系统启动时连接池所创建的连接数。如果创建过多，则系统启动就慢，但创建后系统的响应速度会很快;如果创建过少，则系统启动的很 快，
响应起来却慢。这样，可以在开发时，设置较小的最小连接数，开发起来会快，而在系统实际使用时设置较大的，因为这样对访问客户来说速度会快些。
最大连 接数是连接池中允许连接的最大数目，具体设置多少，要看系统的访问量，可通过反复测试，找到最佳点。
如何确保连接池中的最小连接数呢?有动态和静态两种策略。动态即每隔一定时间就对连接池进行检测，如果发现连接数量小于最小连接数，则补充相应
数量的新连接,以保证连接池的正常运转。静态是发现空闲连接不够时再去检查。



### web工程乱码
#### 编码问题
（1）在参数的时候出现乱码，如果是get请求可以统一设置tomcat的uri编码处理格式，这样所有的url发送的请求都是以指定格式发送。
（2）request.setCharacterEncoding("UTF-8");主要用户 get/post请求中设置整个servlet的编码格式，好处是防止传递的中文参数乱码。
（3）response.setContentType("text/html;charset=UTF-8"); 主要用于指定当前请求中的内容格式，好处是防止输出内容的时候防止中文乱码。
（4）如果在处理中文乱码中以上方法都解决不了，那就要使用js前段编码两次，后台解码的方式处理。

### 乱码总结
1、浏览器调用jsp，html等页面中文显示乱码
此情况需满足两个要求：
（1）文件本身是以utf-8编辑保存的（myEclipse中在properties中鼠标右键选择utf-8）
（2）浏览器用utf-8解析：

2、通过浏览器调用servlet，页面显示乱码。
Servlet乱码分为request乱码和response乱码；
（1）response乱码问题
解决方法：
在网上很有效的解决方法是添加：
response.setCharacterEncoding("UTF-8");
解决不了，后来又搜到一条解决方法是：
response.setContentType("text/html;charset=utf-8"); 

（2）request乱码问题
request请求分为post和get，对于不同的请求方式有不同的解决乱码的方案；
==>POST请求：
request.setCharacterEncoding（）是设置从request中取得的值或从数据库中取出的值 
==>GET请求(URI方式传递参数乱码)：
出现情况：浏览器访问<a href=""><form method="get">
 如：<a href="/webproject/display.jsp?username=张三&password=123">显示用户名和密码</a>
解决方法：问题本质是get方式传递的参数内容默认编码方式问ISO8859-1，而且使用request.setCharacterEncoding("utf-8")也无法解决问题。
法一：要解决这个问题，修改tomcat服务器的配置文件。修改tomcat目录下的conf/server.xml文件的第43行：
修改前内容：
<Connector port="8080" protocol="HTTP/1.1"
     maxThreads="150"   connectionTimeout="200000"
     redirecPort="8443"/>
修改后内容：
<Connector port="8080" protocol="HTTP/1.1"
     maxThreads="150"   connectionTimeout="200000"
     redirecPort="8443"    URIEncoding="utf-8"/>
法二：String usernameString = new String(username.getBytes("ISO-8859-1"),"UTF-8"); 


request.setCharacterEncoding（）是设置从request中取得的值或从数据库中取出的值 
response.setContentType("text/html;charset=gb2312")是设置页面中为中文编码 
前者是设置动态文字（参数，数据库），后者设置页面静态文字
response.setContentType指定 HTTP 响应的编码,同时指定了浏览器显示的编码. 
response.setCharacterEncoding设置HTTP 响应的编码,如果之前使用response.setContentType设置了编码格式,则使用response.setCharacterEncoding
指定的编码格式覆盖之前的设置.与response.setContentType相同的是,调用此方法,必须在getWriter执行之前或者response被提交之前.

3、调用数据库出现乱码
安装数据的时候选择UTF-8

 
4、在项目中的web.xml中增加过滤器Filter 
<filter> 
<filter-name>CharacterEncodingFilter</filter-name> 
<filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class> 
<init-param> 
<param-name>encoding</param-name> 
<param-value>utf-8</param-value> 
</init-param> 
  <init-param> 
<param-name>forceEncoding</param-name> 
<param-value>true</param-value> 
</init-param> 
</filter> 



#### 怎么优化一个服务器的性能（主要说了优化程序本身，如JVM等；优化数据库查询语句性能；以及负载均衡等）

#### 首先明确gradle跟maven一样，也有一个配置文件，maven里面是叫pom.xml，而在gradle中是叫build.gradle。
### maven命令
mvn -v # 查看maven版本
mvn compile # 编译
mvn test # 测试
mvn package # 打包
mvn clean # 删除 target
mvn install # 安装jar包到本地仓库中
mvn archetype:generate -DgroupId=co.hoteam -DartifactId=Zigbee -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false # 创建一个新工程


### 序列化
- 实现 java.io.Serializable 接口
- 实现 Externalizable 接口， 首先，我们在序列化对象的时候，由于这个类实现了Externalizable 接口，在writeExternal()方法里定义了哪些属性可以序列化，
哪些不可以序列化，所以，对象在经过这里就把规定能被序列化的序列化保存文件，不能序列化的不处理，然后在反序列的时候自动调用readExternal()方法，
根据序列顺序挨个读取进行反序列，并自动封装成对象返回，然后在测试类接收，就完成了反序列。
- 使用 sun 公司的 unsafe 方法序列化，规定 int 要四个字节，不然就 oom



### 消息中间件
##### 消息堆积
消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件有一定的消息堆积能力，消息堆积分以下两种情况：
（a）消息堆积在内存Buffer，一旦超过内存Buffer，可以根据一定的丢弃策略来丢弃消息。
（b）消息堆积到持久化存储系统中，例如DB，KV，文件记录形式。
当消息不能在内存cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力

##### Message Persistence
消息中间件通常采用的几种持久化方式：
持久化到数据库，例如Mysql。
持久化到KV存储，例如levelDB、伯克利DB等KV存储系统。
文件记录形式持久化，例如Kafka，RocketMQ
对内存数据做一个持久化镜像，例如beanstalkd，VisiNotify
(1)、(2)、(3)三种持久化方式都具有将内存队列Buffer进行扩展的能力，(4)只是一个内存的镜像，作用是当Broker挂掉重启后仍然能将之前内存的数据恢复出来。


##### Message Reliablity
影响消息可靠性的几种情况：
(1)Broker正常关闭
(2)Broker异常Crash
(3)OS Crash
(4)机器掉电，但是能立即恢复供电情况。
(5)机器无法开机（可能是cpu、主板、内存等关键设备损坏）
(6)磁盘设备损坏。
(1)、(2)、(3)、(4)四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。
(5)、(6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，
但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。
RocketMQ从3.0版本开始支持同步双写。

##### 回溯消息
回溯消息是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留，并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。
RocketMQ支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。

#### 分布式事务
分布式事务涉及到两阶段提交问题，在数据存储方面的方面必然需要KV存储的支持，因为第二阶段的提交回滚需要修改消息状态，一定涉及到根据Key
去查找Message的动作。RocketMQ在第二阶段绕过了根据Key去查找Message的问题，采用第一阶段发送Prepared消息时，拿到了消息的Offset，
第二阶段通过Offset去访问消息，并修改状态，Offset就是数据的地址。
RocketMQ这种实现事务方式，没有通过KV存储做，而是通过Offset方式，存在一个显著缺陷，即通过Offset更改数据，会令系统的脏页过多，需要特别关注。
RocketMQ采取了一种数据与索引分离的存储方法。有效降低文件资源、IO资源，内存资源的损耗。即便是阿里这种海量数据，高并发场景也能够
有效降低端到端延迟，并具备较强的横向扩展能力。

#### Redis分布式锁
以下是一种比较普遍但不太完善的Redis分布式锁的实现步骤（与下图一一对应）：
1. 线程A发送SETNX lock.orderid 尝试获得锁，如果锁不存在，则set并获得锁。
2. 如果锁存在，则再判断锁的值（时间戳）是否大于当前时间，如果没有超时，则等待一下再重试。
3. 如果已经超时了，在用GETSET lock.{orderid} 来尝试获取锁，如果这时候拿到的时间戳仍旧超时，则说明已经获得锁了。
4. 如果在此之前，另一个线程C快一步执行了上面的操作，那么A拿到的时间戳是个未超时的值，这时A没有如期获得锁，需要再次等待或重试。


#### 幂等性问题
所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。扩展一下，这里的接口，可以理解为对外发布的HTTP接口或者Thrift
接口，也可以是接收消息的内部接口，甚至是一个内部方法或操作。
那么我们为什么需要接口具有幂等性呢？设想一下以下情形：
    在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。
在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。
    在分布式环境中，网络环境更加复杂，因前端操作抖动、网络故障、消息重复、响应速度慢等原因，对接口的重复调用概率会比集中式环境下更大，
尤其是重复消息在分布式环境中很难避免。

分布式环境中，有些接口是天然保证幂等性的，如查询操作。有些对数据的修改是一个常量，并且无其他记录和操作，那也可以说是具有幂等性的。
其他情况下，所有涉及对数据的修改、状态的变更就都有必要防止重复性操作的发生。通过间接的实现接口的幂等性来防止重复操作所带来的影响，
成为了一种有效的解决方案。

GTIS的实现思路是将每一个不同的业务操作赋予其唯一性。这个唯一性是通过对不同操作所对应的唯一的内容特性生成一个唯一的全局ID来实现的。
基本原则为：相同的操作生成相同的全局ID；不同的操作生成不同的全局ID。
生成的全局ID需要存储在外部存储引擎中，数据库、Redis亦或是Tair等等均可实现。考虑到Tair天生分布式和持久化的优势，目前的GTIS存储在Tair中。
其相应的key和value如下：
key：将对于不同的业务，采用APP_KEY+业务操作内容特性生成一个唯一标识trans_contents。然后对唯一标识进行加密生成全局ID作为Key。
value：current_timestamp + trans_contents，current_timestamp用于标识当前的操作线程。
判断是否重复，主要利用Tair的SETNX方法，如果原来没有值则set且返回成功，如果已经有值则返回失败。


### 设计一个系统
###### 第一步：确定约束和适用场景（Constraints and Use Cases）
和解答算法题一样，设计题在开始着手思考解决方案之前，最好不断地向面试官提问，彻底搞清楚问题之后再开始解答。对于算法题，一个经典的例子
是，面试官让写一个排序算法。你可以问需要对什么进行排序，整数？浮点数？字符串？然后面试官告诉你需要排序的是员工的年龄。那么问题就一下子
简化了，你本来可能想着是写个快排还是归并排序呢？这下需求彻底搞清楚之后就可以用很简单的桶排序或者基数排序了。
所以，切记，正式开始解题前先彻底理解需求！首先，你需要弄清楚系统的限制，并找出一些系统需要适用的场景。有时候面试官会故意先把系统要求
说得很含糊，他会期望看到，你面对难题时能否注意到系统的要求并在设计方案中解决它们。
###### 第二步：抽象设计（Abstract Design）
完成了第一步之后，你大概就清楚了你要设计的系统以及所需解决的具体问题。所以，接下来你要给出一个高层的抽象设计。你需要列出这个系统所需
要的所有重要组件，以及各个组件之间的联系，有条件的话可以画一个草图。
这个时候面试官可能会给你一些反馈，你可以反驳或者修改你的高层设计，但是绝对不要被他引入到具体细节的讨论中去。在介绍抽象设计时可以返
回去检查一下，所有的use cases是不是都被覆盖了。
###### 第三部：找到瓶颈（Understanding Bottlenecks）
一般情况下，我们不大可能立即找到一个完美的设计，如果发现你的设计在某些情况下不能正常处理或者可能会有性能问题，也不要急于推翻它。这一步，
我们要做的就是找到抽象设计里的这些瓶颈，然后对它们进行分析，尝试提出解决方案。如果设计中存在多处瓶颈问题，也不一定要全部分析，面试官
感兴趣的话可能会跟你深入探讨其中一个。值得一提的是，有时候你的解决方案可能解决了刚提到的瓶颈，但是又会引入新的问题，这时候也不要急于
否定。你可以根据前面列出use cases和constraints来分析不同的问题对系统的影响，权衡具体的解决方案。
###### 第四部：扩展抽象设计（Scaling Your Abstract Design）
接下来就是详细扩展你的设计来解决这些瓶颈了。这里需要用到的就是一些常用的扩展原则，这就需要靠平时的积累了。
首先，需要了解一些关于scalability的理论知识。或者负载均衡、多用户、大数据的处理方案等。

#### 考察内容
1 并发性(concurrency)。你知道线程(threads)、死锁（deadlock）和starvation吗？你知道如何并行化算法吗？你了解一致性(consistency)和
连贯性(coherence)吗？你大概了解IPC和TCP/IP吗？你知道吞吐量（throughput） 和延迟（latency）的区别吗？
2 现实表现(real-word performance)。你应当熟悉你电脑的速度和性能，包括RAM、硬盘、SSD以及你的网络状况。
3 估计(estimation)。估计在帮助你缩小可能性解决方案的范围时起到了重要的作用。这样，你就只需写少数几个原型或微基准。
4 可用性和可靠性(availability and reliability)。你是否考虑过系统什么时候会出现bug无法运行吗（特别是在分散式的环境中）？你知道如何
设计一个系统以应当网络故障吗？你了解持久性吗？切记，我们并不是要寻找一个熟悉以上所有的问题的“全才”。我们想衡量的是你的熟练程度。我们
只需要你对系统设计方面有一定的基础，并且知道什么时候应该寻求专家的帮助。



###  程序员面试
如何说自己缺点
1. 不懂如何拒绝别人，同事让帮忙但是会影响自己进度，不知道该说什么
2. 目前花了比较多的时间在 web 写代码能力上，对数学花的时间少了一些，感觉自己数学方面没有学到精髓部分，比如我们专业学的微积分、概率论都是大学的
基础课程，没有深入探究数论等高深问题，当然我现在也经常做一下算法题来加强我思维能力。

##### 你觉得你个性上最大的优点是什么？ 回答提示：可靠，值得信赖。沉着冷静

你对加班的看法？ 回答提示：实际上好多公司问这个问题，并不证明一定要加班，只是想测试你是否愿意为公司奉献。 回答样本：如果是工作需要我
会义不容辞加班，我现在单身，没有任何家庭负担，可以全身心的投入工作。但同时，我也会提高工作效率，减少不必要的加班。

8、你还有什么问题要问吗？ 回答提示：企业的这个问题看上去可有可无，其实很关键，企业不喜欢说“没问题”的人，因为其很注重员工的个性和创新
能力。企业不喜欢求职者问个人福利之类的问题，如果有人这样问：贵公司对新入公司的员工有没有什么培训项目，我可以参加吗？或者说贵公司的
晋升机制是什么样的？企业将很欢迎，因为体现出你对学习的热情和对公司的忠诚度以及你的上进心。

9、如果通过这次面试我们单位录用了你，但工作一段时间却发现你根本不适合这个职位，你怎么办？ 回答提示：一段时间发现工作不适合我，
有两种情况：①如果你确实热爱这个职业，那你就要不断学习，虚心向领导和同事学习业务知识和处事经验，了解这个职业的精神内涵和职业要求，
力争减少差距；②你觉得这个职业可有可无，那还是趁早换个职业，去发现适合你的，你热爱的职业，那样你的发展前途也会大点，对单位和个人都有好处。
21、最能概括你自己的三个词是什么？ 回答提示：我经常用的三个词是：适应能力强，有责任心和做事有始终，结合具体例子向主考官解释，

#### 5年计划
我从一个小公司来到腾讯，在这样一个大的平台，能够向周围优秀的同事们学习，学习腾讯的文化，通过追赶他们，让自己成为一个更加职业化、
专业化的职业人，我觉得这是难得的一次机会。所以我会在接下来的三年里，让自己从他们身上学到更多，扎根在腾讯，在业务上做出更多的成绩，
让自己在专业领域更有影响力。 
谁还能没有职位的预期呢？但是我觉得职位和薪酬都是你到那个水平，组织自然会考虑到的。所以在职的管理人员必然有他的过人之处，我觉得在我
获得组织的认可之后，一切都是水到渠成的。在职之前，我觉得更应该考虑的是如何扎根在这，成长起来，承担起自己的职责，让自己更有影响力。
 

