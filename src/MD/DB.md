## 数据库
数据批量插入、数据库连接池、查询 select 不要所有字段、经常查询建索引、
能用 join 不要建临时表、静止自动提交、Explain 分析执行计划、插入数据先删索引，插入后再建索引
### psql 性能调优
#### 查询优化
查询是数据库中最频繁的操作，优化查询语句可以有效提高数据库的性能。
- 使用`explain语句分析语句的执行计划`，查看索引使用情况
explain analyze select * from test_table1 where name='bruce.wu'
查看第一步的分析结果，在查询条件使用的列上创建索引
- 优化子查询
子查询很灵活可以极大的节省查询的步骤，但是子查询的执行效率不高。执行子查询时数据库需要为内部嵌套的语句查询的结果建立一个临时表，
然后再使用临时表中的数据进行查询。查询完成后再删除这个临时表，所以子查询的速度会慢一点。
我们可以`使用join语句来替换掉子查询`，来提高效率。join语句不需要建立临时表，所以其查询速度会优于子查询。大部分的不是很复杂的子查询都可以替换成join语句。
如：
select * from a1 where a1.id in (select b1.a1_id from b1)
select a1.* from a1 inner join b1 on a1.id=b1.a1_id
上面两句是等效的，但是inner join 语句效率更高
- 优化数据库结构
`将字段很多的表分解成多个表`
对于字段很多的表，如果有些字段在查询结果中的不常用到，可以将这些字段分离出来形成新的表。因为一个表的数据量很大时，查询会优于使用频率低的字段存在而变慢。
- 增加中间表
对于经常联合查询的表，可以建立一个中间表，把需要经常联合查询的数据插入到中间表，然后将联合查询改为对中间表的查询，来提高查询速度。
- 增加冗余字段
在设计数据库时应尽量遵循数据库设计范式，减少冗余字段，但是合理的冗余字段可以减少不必要的表关联查询，所以，适当的增加冗余字段也是可以提高查询效率的。
- 优化插入记录的速度
插入记录时，影响速度的主要是`索引、唯一性校验、一次性插入条数`等。根据这些情况分别优化
`插入大量数据时先删除索引，完成后再重新创建索引` `删除外键约束`
使用`批量插入`一条insert into 语句可以插入多条数据
- 禁止自动提交
如果允许每个插入都独立的提交，那么数据库就要为每行记录做大量的处理。所以在插入大量数据前禁止自动事务的自动提交，`完成后再恢复自动提交。`
- 使用copy语句批量导入
`copy语句导入数据的速度要比insert语句快。`在大量装载数据的情况下，导致的负载也少很多。
COPY命令是为装载数量巨大的数据行优化过的，它不像INSERT命令那样灵活，但是在装载大量数据时，系统开销也要少很多。因为COPY是单条命令，因此在填充表的时候就没有必要关闭自动提交了。 
- 增大maintenance_work_mem：
在装载大量数据时，临时增大maintenance_work_mem系统变量的值可以改进性能。这个系统参数可以提高CREATE INDEX命令和ALTER TABLE ADD FOREIGN KEY命令的执行效率，但是它不会对COPY操作本身产生多大的影响。
- 增大checkpoint_segments：
临时增大checkpoint_segments系统变量的值也可以提高大量数据装载的效率。这是因为在向PostgreSQL装载大量数据时，将会导致检查点操作
(由系统变量checkpoint_timeout声明)比平时更加频繁的发生。在每次检查点发生时，所有的脏数据都必须flush到磁盘上。通过提高checkpoint_segments变量的值，可以有效的减少检查点的数目。
- 事后运行ANALYZE：
`在增加或者更新了大量数据之后，应该立即运行ANALYZE命令`，这样可以保证规划器得到基于该表的最新数据统计。换句话说，如果没有统计数据或者统计数据太过陈旧，那么规划器很可能会选择一个较差的查询规划，从而导致查询效率过于低下。

### Mysql 性能优化
参考 [MySQL性能优化的21个最佳实践]
1. 为查询缓存优化你的查询
2. EXPLAIN 你的 SELECT 查询
3. 当只要一行数据时使用 LIMIT 1
4. 为搜索字段建索引 　　
`索引并不一定就是给主键或是唯一的字段`。如果在你的表中，有某个字段你总要会经常用来做搜索，那么，请为其建立索引吧。
5. 在Join表的时候使用`相当类型的列`，并将其索引 　　
如果你的应用程序有很多 JOIN 查询，你应该确认两个表中Join的字段是被建过索引的。这样，MySQL内部会启动为你优化Join的SQL语句的机制。
6. 千万不要 ORDER BY RAND()
7. `避免 SELECT *`
需要什么就取什么
8. 永远为每张表设置一个ID 　　
我们应该为数据库里的每张表都设置一个ID做为其主键，而且最好的是一个INT型的(推荐使用UNSIGNED)，并设置上自动增加的AUTO_INCREMENT标志。
9. 使用 ENUM 而不是 VARCHAR 　　
ENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。 　　如果你有一个字段，比如“性别”，“国家”，“民族”，“状态”或“部门”，你知道这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是 VARCHAR。
10. 从 PROCEDURE ANALYSE() 取得建议 　　
PROCEDURE ANALYSE() 会让 MySQL 帮你去分析你的字段和其实际的数据，并会给你一些有用的建议。只有表中有实际的数据，这些建议才会变得有用，因为要做一些大的决定是需要有数据作为基础的。 　　例如，如果你创建了一个 INT 字段作为你的主键，然而并没有太多的数据，那么，PROCEDURE ANALYSE()会建议你把这个字段的类型改成 MEDIUMINT 。或是你使用了一个 VARCHAR 字段，因为数据不多，你可能会得到一个让你把它改成 ENUM 的建议。这些建议，都是可能因为数据不够多，所以决策做得就不够准。
11. 尽可能的使用 NOT NULL
12. Prepared Statements 　　
Prepared Statements很像存储过程，是一种运行在后台的SQL语句集合，我们可以从使用 prepared statements 获得很多好处，无论是性能问题还是安全问题。 　　Prepared Statements 可以检查一些你绑定好的变量，这样可以保护你的程序不会受到“SQL注入式”攻击。当然，你也可以手动地检查你的这些变量，然而，手动的检查容易出问题，而且很经常会被程序员忘了。当我们使用一些framework或是ORM的时候，这样的问题会好一些。 　　在性能方面，当一个相同的查询被使用多次的时候，这会为你带来可观的性能优势。你可以给这些Prepared Statements定义一些参数，而MySQL只会解析一次。
14. 把IP地址存成 UNSIGNED INT 　　
很多程序员都会创建一个 VARCHAR(15) 字段来存放字符串形式的IP而不是整形的IP。如果你用整形来存放，只需要4个字节，并且你可以有定长的字段。而且，这会为你带来查询上的优势，尤其是当你需要使用这样的WHERE条件：IP between ip1 and ip2。 　　我们必需要使用UNSIGNED INT，因为 IP地址会使用整个32位的无符号整形。
15. 固定长度的表会更快 　　
如果表中的所有字段都是“固定长度”的，整个表会被认为是 “static” 或 “fixed-length”。 例如，表中没有如下类型的字段： VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。
16. 垂直分割 　　
“垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。(以前，在银行做过项目，见过一张表有100多个字段，很恐怖)
17. 拆分大的 DELETE 或 INSERT 语句 　　
如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个
操作是会锁表的，表一锁住了，别的操作都进不来了。 　　Apache 会有很多的子进程或线程。所以，其工作起来相当有效率，而我们的服务器也不希
望有太多的子进程，线程和数据库链接，这是极大的占服务器资源的事情，尤其是内存。 　　如果你把你的表锁上一段时间，比如30秒钟，那么对于
一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让你泊WEB服务Crash，还可能会让你的
整台服务器马上掛了。 　　所以，如果你有一个大的处理，你定你一定把其拆分，使用 `LIMIT 条件`是一个好的方法。 while 循环删除。
18. 越小的列会越快 　　
对于大多数的数据库引擎来说，硬盘操作可能是最重大的瓶颈。所以，把你的数据变得紧凑会对这种情况非常有帮助，因为这减少了对硬盘的访问。 　　
如果一个表只会有几列罢了(比如说字典表，配置表)，那么，我们就没有理由使用 INT 来做主键，使用 `MEDIUMINT, SMALLINT 或是更小的 TINYINT `
会更经济一些。如果你不需要记录时间，使用` DATE 要比 DATETIME 好得多。`
19. 选择正确的存储引擎 　　
在 MySQL 中有两个存储引擎 MyISAM 和 InnoDB，每个引擎都有利有弊。
- MyISAM 适合于一些需要`大量查询`的应用，但其对于有大量写操作并不是很好。`甚至你只是需要update一个字段，整个表都会被锁起来`，而别的进程，就算是读进程都无法操作直到读操作完成。另外，`MyISAM 对于 SELECT COUNT(*) 这类的计算是超快无比的`。 　　
- InnoDB 的趋势会是一个非常复杂的存储引擎，对于一些小的应用，它会比 MyISAM 还慢。他是它支持`“行锁” `，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：`事务`
20. 使用一个对象关系映射器(Object Relational Mapper) 　　
使用 ORM (Object Relational Mapper)，你能够获得可靠的性能增涨。一个ORM可以做的所有事情，也能被手动的编写出来。但是，这需要一个高级专家。 　　
`ORM 的最重要的是“Lazy Loading”，`也就是说，只有在需要的去取值的时候才会去真正的去做。但你也需要小心这种机制的副作用，因为这很有可能会因为要去创建很多很多小的查询反而会降低性能。 　　ORM 还可以把你的SQL语句打包成一个事务，这会比单独执行他们快得多得多。
21. 小心“永久链接” 　　
“永久链接”的目的是用来减少重新创建MySQL链接的次数。当一个链接被创建了，它会永远处在连接的状态，就算是数据库操作已经结束了。
而且，自从我们的Apache开始重用它的子进程后——也就是说，下一次的HTTP请求会重用Apache的子进程，并重用相同的 MySQL 链接。
感觉像连接池。


### Mysql 组合索引的最左优先原则：
组合索引 index_a_b_c 可匹配  `a ab abc`
最左匹配原则，就是最左优先，依次向右匹配，直到遇见范围查询（> < between like）就停止；
组合索引的第一个字段必须出现在查询组句中，这个索引才会被用到。
如果有一个组合索引(col_a,col_b,col_c)

下面的情况都会用到这个索引：
col_a = "some value";
col_a = "some value"  and col_c = "some value";
col_a = "some value" and col_b = "some value";
col_a = "some value" and col_b = "some value" and col_c = "some value";
1=1 and col_a=1 and col_b=1
对于最后一条语句，mysql会自动优化成第三条的样子~~。

下面的情况就不会用到索引：
col_b = "aaaaaa";
col_b = "aaaa" and col_c = "cccccc";
col_b = "some value" and col_a = "some value" and col_c = "some value";

表示查询的access type,表示查询是否为”全表扫描“，”索引扫描“等
常见以下几种类型，查询效率由最差到最好
all<index<range ~ index_merge< ref<eq_ref<const<system(效率理论从最差到最好）
                              
5.1 ALL 表示”全表扫描”(full table scan), 性能是最差的几种查询之一，如果查询的表比较大，且查询频次高，对MySQL数据库有致命的性能影响。
见下图：因last_update字段没有索引，帮整体是全表扫描， 扫描rows 200条
5.2 index 表示“全索引扫描”(full index scan)，其类型和ALL较类似，性能也是比较差; 和ALL区别在于只对索引树进行扫描，但索引没有起到过滤作用。
5.3`range` 表示“索引范围扫描”， 通过索引字段范围获取表中部分数据记录； `常常用于in,>,< between等操作`，查询效率一般不错。 下图rows只扫描了4行数据，就获取到指定数据
5.4 index_merge MySQL查询优化器发现查询可以同时使用多个索引查询结果集进行并集或交集的情况，就会使用index_merge type。
此时key字段有两个或多个索引， key_len/rows都分别有两个数值； 如果是并集操作”Using intersect”, 往往通过两个索引的字段，合并为一个索引，避免index_merge查询
下图中两个SQL一个是AND/OR, Using intersect 和Using union 分别表示使用两个索引后的交集和并集
5.5 `ref 针对于非唯一或主键索引，或使用二者”最左部分字段”`索引的等值查询或多表join，查询效率由这个值返回的行数多少决定
5.6 eq_ref 使用于多表的join时，被驱动表的过滤字段是主键或唯一索引，查询效率很好
5.7 const 针对主键或唯一索引的等值查询扫描，最多只返回一行数据
5.8 system: 是一种特殊const类型，被查询表中有且只有一条数据




### mysql 2种引擎  InnoDB 引擎  MyIsam 引擎
####（1）InnoDB：
定义：（默认的存储引擎）
InnoDB是一个`事务型`的存储引擎，有`行级锁定`和`外键约束`。
Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别
该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，
MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。
//这个就是select锁表的一种，不明确主键。增删改查都可能会导致锁全表，在以后我们会详细列出。
SELECT * FROM products WHERE name='Mouse' FOR UPDATE;
适用场景：
1）经常更新的表，适合处理多重并发的更新请求。
2）支持事务。
3）可以从灾难中恢复（通过bin-log日志等）。
4）外键约束。只有他支持外键。
5）支持自动增加列属性auto_increment。


#### 什么叫事务？简称ACID Atomicity Consistency Isolation Durability
- A 事务的原子性(Atomicity)：指一个事务要么全部执行,要么不执行.也就是说一个事务不可能只执行了一半就停止了.比如你从取款机取钱,这个事务可以分成两个步骤:1划卡,2出钱.不可能划了卡,而钱却没出来.这两步必须同时完成.要么就不完成.
- C 事务的一致性(Consistency)：指事务的运行并不改变数据库中数据的一致性.例如,完整性约束了a+b=10,一个事务改变了a,那么b也应该随之改变.
- I 独立性(Isolation）:事务的独立性也有称作隔离性,是指两个以上的事务不会出现交错执行的状态.因为这样可能会导致数据不一致.
- D 持久性(Durability）:事务的持久性是指事务执行成功以后,该事务所对数据库所作的更改便是持久的`保存在数据库`之中，不会无缘无故的回滚.


#### MyIsam：
定义：
MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。
MyIsam 存储引擎独立于操作系统，也就是可以在windows上使用，也可以比较简单的将数据转移到linux操作系统上去。
适用场景：
1）不支持事务的设计，但是并不代表着有事务操作的项目不能用MyIsam存储引擎，可以在service层进行根据自己的业务需求进行相应的控制。
2）不支持外键的表设计。
3）查询速度很快，如果数据库insert和update的操作比较多的话比较适用。
4）整天 对表进行加锁的场景。
5）MyISAM极度强调`快速读取`操作。
6）MyIASM中`存储了表的行数`，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择。
缺点：
就是不能在表损坏后恢复数据。（是不能主动恢复）



### Postgre Sql VS Mysql
#### MySQL的主要优点 （`速度，流行，window，线程，事务`）
1、 首先是速度，MySQL通常要比PostgreSQL快得多。MySQL自已也宣称速度是他们追求的主要目标之一，基于这个原因，MySQL在以前的文档中也曾经说过并不准备支持事务和触发器。
2、MySQL比PostgreSQL更流行，流行意味着更多的用户，意味着经受了更多的考验，意味着更好的`商业支持`。而且MySQL提供了多个不同的社区版、商业版与企业版，而PG只提供了单个完整功能的版本。
3、 与PostgreSQL相比，MySQL更适宜在Windows环境下运行。PostgreSQL在Windows下运 行没有MySQL稳定。
4、MySQL使用了线程，而PostgreSQL使用的是进程。在不同线程之间的环境转换和访问公用的存储区域显然要比在不同的进程之间要`快`得多。
5、由于MySQL 4.0.2-alpha开始支持事务的概念，因此事务对于MySQL不再成为劣势。相反，因为MySQL保留无事务的表类型。这就为用户提供了更多的选择。

#### PostgreSQL的主要优点：  （`协议，规范，可靠，进程，查询`）
1、PG遵循的是BSD协议，完全开源免费且不会被任何商业公司控制；而MySQL在oracle手中，慢慢走向封闭。
2、PostgreSQL源代码堪称C语言的规范，`易读性`比MySQL强很多。
3、`可靠性`是PostgreSQL的最高优先级。它以坚如磐石的品质和良好的工程化而闻名。`PostgreSQL是完全支持ACID特性`的，对于数据库访问提供了强大的安全性保证。
4、PG是`多进程`的，而My是多线程的。虽然并发不高时，My处理速度快；但是当并发高时，对于现在的`多核的单台机器`上，My的总体性能不如PG，原因是My的线程无法充分利用CPU的能力。
5、PG有很强大的`查询优化器(explain)`，`支持很复杂的查询处理(with写法)`，而My对复杂查询处理较弱，查询优化器不够成熟。

#### MySQL or PG
1、如果你的操作系统是Windows，你应该使用MySQL。
2、如果你的应用对数据的完整性和严肃性要求不高，但是追求处理的高速度。例如是一个论坛和社区，你应该使用MySQL。
3、你的应用是一个严肃的商业应用，对数据完整性要求很高，并且需要开源免费的数据库，你应该使用PostgreSQL。
4、你是一个数据库内核的狂热爱好者，你甚至希望拥有你自己版本的数据库，毫无疑问，你必须使用PostgreSQL，没准下一个PostgreSQL版本中某一个模块的作者就是你。


### varchar和text： 
1.varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个字节（n<=255）或2个字节(n>255)，text是实际字符数+2个字节。 
2.text类型不能有默认值。 
3.varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速度快于text,在都创建索引的情况下，text的索引似乎不起作用。

### 数据库四个范式的区别
参考[数据范式区别]
1. 第一范式（1NF）：`属性不可拆分` 或 无重复的列
这个简单，就是一个属性不允许再分成多个属性来建立列。事实上，在目前的DBMS中是不可能拆分属性的，因为他们不允许这么做。
2. 第二范式（2NF）：`完全函数依赖`
先讲讲什么是部分函数依赖。
部分函数依赖，就是多个属性决定另一个属性，但事实上，这多个属性是有冗余的。例如，（学号，班级）->姓名，事实上，只需要学号就能决定姓名，因此班级是冗余的，应该去掉。
满足第二范式的数据库设计必须先满足第一范式。
因此第二范式的目标就是消除函数依赖关系中左边存在的冗余属性。
3.第三范式（3NF）：`消除传递依赖`
不依赖于其他非主属性（消除传递依赖）。
满足第三范式的数据库必须先满足第二范式。
也就是，数据库中的属性依赖仅能依赖于主属性，不存在于其他非主属性的关联。
例如，图书，图书室的关系。图书包括编号、出版商、页码等信息，图书室包括图书室编号、所存图书（外键）。其中，图书室的表中不应该存储任何
图书的具体信息（例如，出版商。。），而只能通过主键图书编号来获得对应图书的信息。
4.BC范式（BCNF）：
（1）所有非主属性对每一个码都是完全函数依赖；
（2）所有的主属性对于每一个不包含它的码，也是完全函数依赖；
（3）没有任何属性完全函数依赖于非码的任意一个组合。
R属于3NF，不一定属于BCNF，如果R属于BCNF，一定属于3NF。
5.第四范式（4NF）：`消除多值依赖`
对于每一个X->Y，X都能找到一个候选码（ 若关系中的某一属性组的值能唯一地表示一个元组,而其真子集不行,则称该属性组为候选码）。
最后举个例子（网上的）：
学生表
学号
姓名
教师学生关系编号
系编号
爱好编号
一范式，就是表里的字段不能在划分属性了。
二范式，满足一范式基础，表里不存在与学号没关系的信息
三范式，满足二范式的基础上，表里不存在其他字段的关联，
BC范式，满足三范式的基础上，就是学生表里的每行都不存在重复的信息
第四范式，满足BC范式，就是连爱好这样字段，也不能出现 ”篮球，足球“；要建立一个爱好编号表，


### MySql 事务隔离级别

=================================================================================================================
       隔离级别               脏读（Dirty Read）          不可重复读（NonRepeatable Read）     幻读（Phantom Read） 
==================================================================================================================
未提交读（Read uncommitted）        可能                            可能                       可能
已提交读（Read committed）          不可能                          可能                       可能
可重复读（Repeatable read）         不可能                          不可能                     可能
可串行化（Serializable ）           不可能                          不可能                     不可能
===================================================================================================================
·未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中`未提交事务修改的数据`
·提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)
·可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，`InnoDB默认级别。`在SQL标准中，该隔离级别消除了
不可重复读，但是还存在幻象读
·串行读(Serializable)：`完全串行化的读`，每次读都需要获得`表级共享锁`，`读写相互都会阻塞`

① 脏读: 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改`还没有提交到数据库中`，这时，另外一个事务也访问这个数据，
然后使用了这个数据。
② 不可重复读:是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据
之间，由于第二个事务的修改，那么`第一个事务两次读到的的数据可能是不一样的`。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。
③ 幻读:第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中
`插入一行新数据。`那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。
④ 丢失修改：两个事务T1和T2读入同一数据并修改，T2提交的结果破坏了T1提交的结果，导致T1的修改被丢失。

#### 不可重复读和幻读的区别
很多人容易搞混不可重复读和幻读，确实这两者有些相似。但`不可重复读重点在于update和delete`，而`幻读的重点在于insert。`
如果使用锁机制来实现这两种隔离级别，`在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现
可重复读了。`但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时
事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，`不能通过行锁来避免`。
- 需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。

- 行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁（间隙锁）结合形成的的Next-Key锁共同解决了RR(可重复读)级别在写数据时
的幻读问题。




### 事务在加锁时有多种方式：
一次性锁协议，事务开始时，即一次性申请所有的锁，之后不会再申请任何锁，如果其中某个锁不可用，则整个申请就不成功，事务就不会执行，在
事务尾端，一次性释放所有的锁。一次性锁协议不会产生死锁的问题，但事务的并发度不高。
两阶段锁协议，整个事务分为两个阶段，前一个阶段为加锁，后一个阶段为解锁。在加锁阶段，事务只能加锁，也可以操作数据，但不能解锁，直到
事务释放第一个锁，就进入解锁阶段，此过程中事务只能解锁，也可以操作数据，不能再加锁。两阶段锁协议使得事务具有较高的并发度，因为解锁不必发生在事务结尾。它的不足是没有解决死锁的问题，因为它在加锁阶段没有顺序要求。如两个事务分别申请了A, B锁，接着又申请对方的锁，此时进入死锁状态。


### 索引与主键的区别
主键：主键是唯一的，用于快速定位一条记录。 
聚集索引：聚集索引也是唯一的。（因为聚集索引的划分依据是物理存储）。而聚集索引的主要是为了快速的缩小查找范围，即记录数目未定。 
主键和索引没有关系。他们的用途相近。如果聚集索引加上唯一性约束之后，他们的作用就一样了。
　
### 关于索引的使用与优化有下面的一些准则:
- 当在建立了索引的列上使用精确匹配，`使用“=”或者“in”时是会使用索引的`。
- `最左匹配原则`，在a和b上建立了联合索引，where b = ?时是不会使用告警的。
- `通配符%不能放在开头`，也就是说，like %abc%是不会使用索引的，like abc%是会使用索引的。
- 范围列(>,<,between and)可以用到索引，但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。
- 如果使用了函数或者表达式，则不会使用索引。例如，left(title, 6)='Senior'将不会使用到索引，可以使用like代替。
- group by的优化需要松散索引扫描和紧凑索引扫描，单独地进行说明。

### 聚集索引(clustered index)和非聚集索引
- 聚集索引：该索引中键值的`逻辑顺序决定了表中相应行的物理顺序`。
聚集索引确定表中数据的物理顺序。聚集索引类似于电话簿，后者按姓氏排列数据。由于聚集索引规定数据在表中的物理存储顺序，因此一个表只能
包含一个聚集索引。但该索引可以包含多个列（组合索引），就像电话簿按姓氏和名字进行组织一样。
- 非聚集索引：数据存储在一个地方，索引存储在另一个地方，`索引带有指针指向数据的存储位置`。
聚集索引中的项目按索引键值的顺序存储，而表中的信息按另一种顺序存储（这可以由聚集索引规定）。对于非聚集索引，可以为在表非聚集索引中查找数据时常用的每个列创建一个非聚集索引。有些书籍包含多个索引。例如，一本介绍园艺的书可能会包含一个植物通俗名称索引，和一个植物学名索引，因为这是读者查找信息的两种最常用的方法。

`聚集索引：可以帮助把很大的范围，迅速减小范围。但是查找该记录，就要从这个小范围中Scan了。` 
非聚集索引：把一个很大的范围，转换成一个`小的地图`。你需要在这个小地图中找你要寻找的`信息的位置`。然后通过这个位置，再去找你所需要的记录。

### 聚集主键有助于性能，但是它也能导致严重的性能问题。

优点：
1，可以把相关数据保存在一起。
2，数据访问快。聚集索引把索引和数据都保存到同一棵B+Tree中，因此从聚集索引中取得数据通常在非聚集索引进行查找要快。
3，使用覆盖索引的查询可以使用包含在叶子节点中的主键值
如果表和查询可以使用它们，这些优点能极大地提高性能。

缺点：
1，聚集能最大限度地提升I/O密集负载的性能。如果数据能装入内存，那么其顺序也就无怕谓了，这样聚集就没什么用处。
2，插入速度严重依赖于插入顺序。按照主键的顺序插入行是把数据装入InnoDB表最快的方法。如果没有按照主键顺序插入数据，那么在插入之后最好使用OPTIMIZE TABLE重新组织一下表。
3，更新聚集索引列是昂贵的，因为它强制InnoDB把每个更新的迁移到新的位置。
3，建立在聚集索引上的表在插入新行，或者在行的主键被更新，该行必须被移动的时候会进行分页。分布发生在行的键值要求行必须被放到一个已经放满了数据的页的时候，此时存储引擎必须分页才能容纳该行。分页会导致表占用更多的磁盘空间
4，聚集表可能会比全表扫描慢，尤其在表存储得比较稀疏或因为分页而没有顺序存储的时候。
5，第二（非聚集）索引可能会比预想的大，因为它们的叶子节点包含了被引用行的主键列。
6，第二索引访问需要两次索引查找，而不是一次（叶子节点不会保存引用的行的物理位置，而是保持了行的主键值）


SQL创建删除索引
--创建唯一聚集索引 create unique clustered index pk_table1 on table1 (column1) 
--创建唯一非聚集索引 create unique nonclustered index IX_table1_column2 on table1(column2) 
--创建不唯一非聚集索引 create index IX_table1_column1 on table1(column1) 
--删除索引 drop index pk_table1 on tab

##### 一棵最小度为t的B树是满足如下四个条件的平衡多叉树：
每个节点最多包含`2t−1个关键字`；除根节点外的每个节点至少有`t−1个关键字`（t≤2），根节点至少有一个关键字；


####  Mysql 里CHAR和VARCHAR的最大长度
非空CHAR的最大总长度是255【字节】2^7 - 1 ；非空VARCHAR的最大总长度是65533【字节】。2^16 - 3             2个字节记录长度
可空CHAR的最大总长度是254【字节】；可空VARCHAR的最大总长度是65532【字节】。
CHAR列的长度固定为创建表时声明的长度。长度可以为从0到255的任何值。当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。
VARCHAR列中的值为可变长字符串。长度可以指定为0到65,535之间的值。(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。
同CHAR对比，VARCHAR值保存时只保存需要的字符数，另加`一个字节`来记录长度(如果列声明的长度超过255，则使用`两个字节`)。
VARCHAR值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。



### RDBMS VS NOSQL
RDBMS	                                    NoSQL
高度组织化结构化数据 	                    代表着不仅仅是SQL
结构化查询语言（SQL） (SQL) 	            没有声明性查询语言
数据和关系都存储在单独的表中	            没有预定义的模式
数据操纵语言，数据定义语言 	            `键 - 值对存储，列存储，文档存储，图形数据库`
严格的一致性	                            最终一致性，而非ACID属性
基础事务	                                非结构化和不可预知的数据
                                        CAP定理
                                        高性能，高可用性和可伸缩性


### NoSql
NoSQL产品有KV（key-value）型、文档型、列存储型、图存储型、对象存储型、XML数据库型等
Key-Value存储:(Redis、Memcached) 使用 key 快速查到 value，Memcached 支持 string 类型的 value，Redis 除 String 类型外还支持 set、hash、sort set、list 等类型
传统的关系型数据库，处理一对多的问题，需要把外键放在多的一端，因为RDBMS理论中没有集合这个概念。`而使用Redis，我们可以在一端来管理
一对多的关系，使用Set。`
如果使用MySQL，当数据规模非常大时，上面两个查询操作都需要借助表关联技术，而大表间的join在大型系统中是需要极力避免的操作。
相反Redis的每个操作都会局限在一个较小的数据集范围内，而且key-value的存储形式，定位key只是一个复杂度为O(1)的操作。在very huge的数据量下，
Redis性能效果非常优异，这就是NoSQL的优势所在！

- 键值(Key-Value)存储数据库
这一类数据库主要会使用到一个`哈希表`，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。[3]
  举例如：Tokyo Cabinet/Tyrant, Redis, Voldemort, Oracle BDB.，Google
  BigTable ，Amazon DynamoDB
- 列存储数据库。
这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。如：Cassandra,
  HBase, Riak.
- 文档型数据库
文档型数据库的灵感是来自于Lotus
  Notes办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可
  以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDb. 国内也有文档型数据库SequoiaDB，已经开源。
- 图形(Graph)数据库
图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API。

#### CAP定理（CAP theorem）
一致性(Consistency) (所有节点在同一时间具有相同的数据)
可用性(Availability) (保证每个请求不管成功或者失败都有响应)
分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作)




### 树
#### 二叉查找树
二叉查找树也称为有序二叉查找树,满足二叉查找树的一般性质,是指一棵空树具有如下性质:
任意节点左子树不为空,则左子树的值均小于根节点的值.
任意节点右子树不为空,则右子树的值均大于于根节点的值.
任意节点的左右子树也分别是二叉查找树.
没有键值相等的节点.

#### AVL树
AVL树是带有平衡条件的二叉查找树,一般是用平衡因子差值判断是否平衡并通过旋转来实现平衡,左右子树树高不超过1,和红黑树相比,它是严格的
平衡二叉树,平衡条件必须满足(所有节点的左右子树高度差不超过1).不管我们是执行插入还是删除操作,只要不满足上面的条件,就要通过旋转来保持
平衡,而旋转是非常耗时的,由此我们可以知道AVL树适合用于插入删除次数比较少，但查找多的情况。

#### 红黑树
一种二叉查找树,但在每个节点增加一个存储位表示节点的颜色,可以是red或black. 通过对任何一条从根到叶子的路径上各个节点着色的方式的限制,
红黑树确保没有一条路径会比其它路径长出两倍.它是一种`弱平衡二叉树(由于是弱平衡`,可以推出,`相同的节点情况下,AVL树的高度低于红黑树`),相对
于要求严格的AVL树来说,它的旋转次数变少,所以对于搜索,插入,删除操作多的情况下,我们就用红黑树.

#### B/B+树
B+树只需要去遍历叶子节点就可以实现整棵树的遍历，而B树还要遍历根节点
注意B-树就是B树,-只是一个符号.
B/B+树是为了磁盘或其它存储设备而设计的一种`平衡多路查找树`(相对于二叉,B树每个内节点有多个分支),与红黑树相比,在相同的的节点的情况下,
一颗B/B+树的高度远远小于红黑树的高度(在下面B/B+树的性能分析中会提到).B/B+树上操作的时间通常由存取磁盘的时间和CPU计算时间这两部分构成,
而CPU的速度非常快,所以B树的操作效率取决于访问磁盘的次数,`关键字总数相同的情况下B树的高度越小，磁盘I/O所花的时间越少`.
##### 为什么说B+tree比B树更适合实际应用中 操作系统的文件索引 和 数据索引.　　
B+-tree的内部节点并没有指向关键字具体信息的指针,因此其内部节点相对B树更小,如果把所有同一内部节点的关键字存放在同一盘块中,那么盘块所
能容纳的关键字数量也越多,`一次性读入内存的需要查找的关键字也就越多,相对IO读写次数就降低了`.
由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。
所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 
他们认为数据库索引采用B+树的主要原因是:`B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题`,正是为了解决这个问题,B+树应用而生.
`B+树只需要去遍历叶子节点就可以实现整棵树的遍历.而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）`.　　
叶子节点是一个链表

### 分库分表
#### 垂直分表
垂直分表在日常开发和设计中比较常见，通俗的说法叫做“大表拆小表”，拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字
段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中
#### 垂直分库
垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。
#### 水平分表
水平分表也称为横向分表，比较容易理解，就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），
这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行Hash和取模后拆分。
#### 水平分库分表
水平分库分表与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据中。

#### 分库分表的难点
垂直分库带来的问题和解决思路：
##### 跨库join的问题
在拆分之前，系统中很多列表和详情页所需的数据是可以通过sql join来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库join的。那该怎么办呢？首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，下面笔者将结合以往的实际经验，总结几种常见的解决思路，并分析其适用场景。
##### 跨库Join的几种解决思路
###### 全局表
所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库join查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。
###### 字段冗余
这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免join查询。
举个电商业务中很简单的场景：
“订单表”中保存“卖家Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。
字段冗余能带来便利，是一种“空间换时间”的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，可以借助数据库中的触发器或者在业务代码层面去保证。当然，也需要结合实际业务场景来看一致性的要求。就像上面例子，如果卖家修改了Name之后，是否需要在订单信息中同步更新呢？
###### 数据同步
定时A库中的tab_a表和B库中tbl_b有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。这样来避免复杂的跨库查询。笔者曾经在项目中是通过ETL工具来实施的。
###### 系统层组装
在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。说起来很容易，但实践起来可真没有这么简单，尤其是数据库设计上存在问题但又无法轻易调整的时候。
具体情况通常会比较复杂。下面笔者结合以往实际经验，并通过伪代码方式来描述。

### SQL中存储过程和函数的区别
1. 一般来说，`存储过程实现的功能要复杂一点，而函数的实现的功能针对性比较强。 `
2. 当对数据库进行复杂操作时(如对多个表进行Update、Insert、Query、Delete时），可将此复杂操作用存储过程封装起来与数据库提供的事务
处理结合一起使用。存储过程可以从自己的存储过程内引用其它存储过程，这可以简化一系列复杂语句.   
3. 存储过程一般是作为一个独立的部分来执行，而函数可以作为查询语句的一个部分来调用，由于函数可以返回一个表对象，因此它可以在查询语句
中位于FROM关键字的后面。
4. 存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，`而一般SQL语句每执行一次就编译一次`,所以使用存储过程可提高数据库执行速度。
5. 存储过程可以接受参数、输出参数、`返回单个或多个结果集以及返回值`，可以向程序返回错误原因。但函数只能返回一个特定类型的值或者表对象。 
6. 存储过程中的CRUD的操作会影响数据库状态，但函数却不能。
本质上没区别。只是函数有如：只能返回一个变量的限制。而存储过程可以返回多个。`而函数是可以嵌入在sql中使用的,可以在select中调用，而存储过程不行`。执行的本质都一样。 
函数限制比较多，比如不能用临时表，只能用表变量．还有一些函数都不可用等等．而存储过程的限制相对就比较少 
存储过程：
   CREATE OR REPLACE PROCEDURE my_proc
   (p_name IN VARCHAR2 := 'John') as begin ... end
    
函数：
   CREATE OR REPLACE FUNCTION my_func
   (p_name IN VARCHAR2 := 'John') return varchar2 as begin ... end

之前 物化视图 那里就是创了一个触发器去执行一个函数更新物化视图

```mysql
CREATE OR REPLACE PROCEDURE get_order_by_cust(IN cust_no INT,
 OUT ord1 INT,
 OUT ord2 INT,
 OUT ord3 INT)
BEGIN
 -- 已完成订单
 SELECT
            count(*) INTO ord1
        FROM
            orders
        WHERE
            customerNumber = cust_no
                AND status = '1';
 -- 取消的订单
 SELECT
            count(*) INTO ord2
        FROM
            orders
        WHERE
            customerNumber = cust_no
                AND status = 2;
 -- 待处理订单
 SELECT
            count(*) INTO ord3
        FROM
            orders
        WHERE
            customerNumber = cust_no
                AND status = '3';
END
```
调用：
```mysql
CALL get_order_by_cust(141,@ord1,@ord2,@ord3);
SELECT @ord1,@ord2,@ord3;
```
结果：
@ord1  @ord2  @ord3
 22      0      1



### 倒排索引(反向索引)
常规的索引是文档到关键词的映射：
           文档——>关键词
倒排索引是关键词到文档的映射
          关键词——>文档
一个未经处理的数据库中，一般是以文档ID作为索引，以文档内容作为记录。
而Inverted index 指的是将单词或记录作为索引，将文档ID作为记录，这样便可以方便地通过单词或记录查找到其所在的文档。
例如:
T0: it is what it is
T1: what is it
T2: it is a banana
倒排索引：
"a":      {2}
"banana": {2}
"is":     {0, 1, 2}
"it":     {0, 1, 2}
"what":   {0, 1}
检索的条件"what", "is" 和 "it" 将对应这个集合：
{0, 1} 交 {0, 1, 2} 交 {0, 1, 2} = {0, 1}  T0 T1
正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。
实际上，时间、内存、处理器等等资源的限制，技术上正向索引是不能实现的。
为了替代正向索引的每个文档的单词列表，能列出`每个查询的单词所有所在文档的列表`的反向索引数据结构开发了出来。



####  MVCC的实现方法有两种：

1.写新数据时，把旧数据移到一个单独的地方，如回滚段中，其他人读数据时，从回滚段中把旧的数据读出来；
2.写数据时，旧数据不删除，而是把新数据插入。
PostgreSQL数据库使用第二种方法，而Oracle数据库和MySQL中的innodb引擎使用的是第一种方法。
与racle数据库和MySQL中的innodb引擎相比较，PostgreSQL的MVCC实现方式的优缺点如下。
优点：
1.事务回滚可以立即完成，无论事务进行了多少操作；
2.数据可以进行很多更新，不必像Oracle和MySQL的Innodb引擎那样需要经常保证回滚段不会被用完，也不会像oracle数据库那样经常遇到“ORA-1555”错误的困扰；
缺点：
1.旧版本数据需要清理。PostgreSQL清理旧版本的命令成为Vacuum；
2.旧版本的数据会导致查询更慢一些，因为旧版本的数据存在于数据文件中，查询时需要扫描更多的数据块。  



### MySQL · 引擎特性 · InnoDB 崩溃恢复过程
InnoDB 采用文件日志的方式，使用日志恢复。



### MySQL 对于千万级的大表要怎么优化？
第一优化你的sql和索引；
第二加缓存，memcached,redis；
第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护；
第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个，对你的应用是透明的，无需更改代码,但是sql语句是需要针对分区表做优化的，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，另外分区表还有一些坑，在这里就不多说了；
第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；
第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；


#### 建索引的几大原则
1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式
3.尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录
4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可
6.like查询是以%开头不匹配，以%结尾的匹配
MySQL只对<，<=，=，>，>=，BETWEEN，IN，以及某些时候的LIKE才会使用索引。
<，<=，=，>，>=，BETWEEN，IN 会使用索引
<>，not in ，！= 则不能够使用索引


### 哪些字段适合建索引
1、表的主键、外键必须有索引；
2、数据量超过300的表应该有索引；
3、`经常与其他表进行连接的表，在连接字段上应该建立索引；`
4、`经常出现在Where子句中的字段，特别是大表的字段，应该建立索引；`
5、索引应该建在选择性高的字段上；
6、`索引应该建在小字段上`，对于大的文本字段甚至超长字段，不要建索引；
7、复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替：
A、正确选择复合索引中的主列字段，一般是选择性较好的字段；
B、复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引；
C、如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引；
D、如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段；
E、如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；
8、频繁进行数据操作的表，不要建立太多的索引；
9、删除无用的索引，避免对执行计划造成负面影响；



### 分区 VS 分表
##### 为什么要分表和分区？
日常开发中我们经常会遇到大表的情况，所谓的大表是指存储了百万级乃至千万级条记录的表。这样的表过于庞大，导致数据库在查询和插入的时候
耗时太长，性能低下，如果涉及联合查询的情况，性能会更加糟糕。分表和表分区的目的就是减少数据库的负担，提高数据库的效率，通常点来讲就是
提高表的增删改查效率。
##### 什么是分表？
分表是将一个大表按照一定的规则分解成多张具有独立存储空间的实体表，我们可以称为子表，每个表都对应三个文件，MYD数据文件，.MYI索引文件，
.frm表结构文件。这些子表可以分布在同一块磁盘上，也可以在不同的机器上。app读写的时候根据事先定义好的规则得到对应的子表名，然后去操作它。
##### 什么是分区？
分区和分表相似，都是按照规则分解表。不同在于分表将大表分解为若干个独立的实体表，而分区是将数据分段划分在多个位置存放，可以是同一块磁盘
也可以在不同的机器。分区后，表面上还是一张表，但数据散列到多个位置了。app读写的时候操作的还是大表名字，db自动去组织分区的数据。
##### mysql分表和分区有什么联系呢？
1. 都能提高mysql的性高，在高并发状态下都有一个良好的表现。
2. 分表和分区不矛盾，可以相互配合的，对于那些大访问量，并且表数据比较多的表，我们可以采取分表和分区结合的方式（如果merge这种分表方式，
不能和分区配合的话，可以用其他的分表试），访问量不大，但是表数据很多的表，我们可以采取分区的方式等。
3. 分表技术是比较麻烦的，需要手动去创建子表，app服务端读写时候需要计算子表名。采用merge好一些，但也要创建子表和配置子表间的union关系。
4. 表分区相对于分表，操作方便，不需要创建子表。

分区的几种方式
1、Range：
```mysql
create table range(   
  id int(11),
  money int(11) unsigned not null,  
  date datetime   
   )partition by range(year(date))(  
  partition p2007 values less than (2008),   
  partition p2008 values less than (2009),   
  partition p2009 values less than (2010)
);
```
2、List：
```mysql
create table list(
  a int(11),
  b int(11)
  ) partition by list (b)(
  partition p0 values in (1,3,5,7,9),
  partition p1 values in (2,4,6,8,0)   
  );
```
3、Hash：
  partition by hash (YEAR(b)  
　partitions 4;  

4、Key：
　partition by key (b)   
　partitions 4;  












[MySQL性能优化的21个最佳实践]:http://www.searchdatabase.com.cn/showcontent_38045.htm
[数据范式区别]:http://blog.csdn.net/yahohi/article/details/7529710