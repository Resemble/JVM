## 网络
参考博客[网络通信面试]
### 三次握手
- 第一次握手：建立连接。客户端发送连接请求报文段，将`SYN`位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；
- 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1
(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段
（即`SYN+ACK`报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；
- 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送`ACK`报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。
#### 为什么要进行三次握手？两次握手不可以吗？为什么？
为了`防止已失效的连接请求报文段突然又传送到了服务端`，因而产生错误。服务器建立连接，然后等待客户端发信息，白白浪费服务器资源。

#### 三次握手的漏洞
1.SYN FLOOD攻击
  DDOS是英文Distributed Denial of Service的缩写，意即"分布式拒绝服务",DDOS的中文名叫分布式拒绝服务攻击，俗称洪水攻击。
  SYN-FLOOD是一种常见的DDos攻击，拒绝服务攻击。通过网络服务所在的端口发送大量伪造原地址的攻击报文，发送到服务端，造成服务端上的半开连接队列被占满，从而阻止其他用户进行访问。
  它的`数据报特征是大量syn包，并且缺少最后一步的ACK回复`。
  原理：攻击者首先伪造地址，对服务器发起syn请求，服务器回应syn+ACK，而真实的IP会认为我没有发送请求，不做回应，而服务端没有收到回应，
  服务器就不知道是否发送成功，`默认情况下重试5次 syn_retries，这样的话`，对于服务器内存和带宽有很大的消耗。


一类是通过防火墙、路由器等过滤网关防护，另一类是通过加固TCP/IP协议栈防范。过滤网关防护主要包括超时设置，SYN网关和SYN代理三种。
调整tcp/ip协议栈，修改tcp协议实现。主要方法有SynAttackProtect保护机制、SYN cookies技术、增加最大半连接和缩短超时时间等。 

2.解决SYN FLOOD方法
(1).无效连接监控
不停监视半开连接和不活动连接，当半开连接数和不活动连接数到达一定值时候，就释放系统资源。
伤敌1000，自损8000
(2).延缓TCB方法
SYN FLOOD的关键是利用了，syn数据报一到，系统就分配TCB(任务控制块 Task Control Block)资源。
那么我们有两种方法资源问题
Syn cache
这种技术在收到Syn时不急着分配TCB，而是先回应一个ACK报文，并在一个专用的HASH表中保存这种连接，`直到收到正确的ACK`，才分配TCB。
(3).Syn Cookie
用一种特殊的算法生成sequence number，算法考虑到对方的信息和己方信息，`收到对方的ACK报文后`，验证之后才决定是否生成TCB


##### 了解的网络攻击手段，可以怎么预防 
  拒绝服务攻击： 
（1）SYN拒绝服务攻击：目标计算机如果接收到大量的TCP SYN报文，而没有收到发起者的第三次ACK回应，会一直等待，处于这样尴尬状态的半连接如果很多，则会把目标计算机的资源（TCB控制结构，TCB，一般情况下是有限的）耗尽，而不能响应正常的TCP连接请求。 
（2）ICMP洪水：。这样如果攻击者向目标计算机发送大量的ICMP ECHO报文（产生ICMP洪水），则目标计算机会忙于处理这些ECHO报文，而无法继续处理其它的网络数据报文，这也是一种拒绝服务攻击（DOS）。 
（3）UDP洪水； 
（4）死亡之PING：TCP/IP规范要求IP报文的长度在一定范围内（比如，0－64K），但有的攻击计算机可能向目标计算机发出大于64K长度的PING报文，导致目标计算机IP协议栈崩溃。 
（5）IP地址欺骗：如果一个攻击者向一台目标计算机发出一个报文，而把报文的源地址填写为第三方的一个IP地址，这样这个报文在到达目标计算机后，目标计算机便可能向毫无知觉的第三方计算机回应。这便是所谓的IP地址欺骗攻击。 


### 四次挥手
#### TIME_WAIT 客户端主动断开，客户端 TIME_WAIT
1.`防止上一次连接中的包，迷路后重新出现`，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）
2.可靠的关闭TCP连接。在主动关闭方发送的最后一个 ack ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，
就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。另外这么设计TIME_WAIT 会定时的回收资源，并不会占用很
大资源的，除非短时间内接受大量请求或者受到攻击。


### HTTPS协议 TLS协议 SSL(Secure socket Layer)协议
- HTTPS协议：Http over SSL
- TLS并不是一个新协议，它是SSL(准确的说是SSL v3)的强化版，在整个协议格式上，和SSL类似
- SSL(Secure socket Layer 安全套接层协议)指使用公钥和私钥技术组合的安全网络通讯协议，
它为TCP/IP连接提供数据加密、服务器认证、消息完整性以及可选的客户机认证，主要用于提高应用程序之间数据的安全性，对传送的数
据进行加密和隐藏，确保数据在传送中不被改变,即确保数据的完整性。
SSL协议位于TCP/IP协议模型的`网络层和应用层`之间，使用TCP来提供一种可靠的端到端的安全服务，它是客户/服务器应用之间的通信
不被攻击窃听，并且始终对服务器进行认证，还可以选择对客户进行认证。
SSL协议应用层来说是透明的，我们在编写基于SSL的HTTPS应用时，无论客户端还是服务端都不需要考虑SSL的存在

### HTTP和HTTPS的区别：
http是超文本传输协议，信息是`明文传输`
https 则是具有安全性的`SSL加密传输协议`
http和https使用的是完全不同的连接方式，用的`端口`也不一样，前者是80，后者是443
http的连接很简单，是无状态的
HTTPS协议是由SSL+HTTP协议构建的可进行`加密传输、身份认证的网络协议`，比http协议安全
使用 https 进行传输数据时
最终 应用层 仍然是使用 http协议
只是不会像以前直接 应用层 ----> 传输层
而是经过SSL层处理，应用层 -----> SSL层 -----> 传输层
SSL层负责对传输数据的加密、完整性验证、双方身份认证

#### Https加密
##### 对称加密
（1）甲方选择某一种加密规则，对信息进行加密；
（2）乙方使用同一种规则，对信息进行解密。
由于加密和解密使用同样规则（简称"密钥"），这被称为"对称加密算法"（Symmetric-key algorithm）。
这种加密模式有一个最大弱点：甲方必须把加密规则告诉乙方，否则无法解密。保存和传递密钥，就成了最头疼的问题。
##### 非对称加密 (RSA)
（1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。
（2）甲方获取乙方的公钥，然后用它对信息加密。
（3）乙方得到加密后的信息，用私钥解密。
如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。
这种算法用他们三个人的名字命名，叫做RSA算法。从那时直到现在，RSA算法一直是最广为使用的"非对称加密算法"。毫不夸张地说，只要有计算机网络的地方，就有RSA算法。


### 网络通讯中，端口有什么含义。端口的取值范围？ 
端口用于区分基于TCP/IP通讯的不同应用程序, `每个基于TCP/IP应用程序都会向操作系统申请注册一个服务，这个服务用端口表示`。
本质上说，`端口就是一段内存中的缓冲区`。可以认为是计算机与外界交流的出口。 
建议用户使用的端口号 1024---65535
系统使用的端口范围   0 --- 1024

### 短连接 长连接
#### 短连接：  
连接->传输数据->关闭连接  
HTTP是无状态的，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。  
也可以这样说：短连接是指SOCKET连接后发送后接收完数据后马上断开连接。  
像`WEB网站的http服务一般都用短链接`，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好
#### 长连接：  
连接->传输数据->保持连接 -> 传输数据-> 。。。 ->关闭连接。  
长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。
长连接多用于操作频繁，点对点的通讯，而且连接数不能太多，例如：`数据库的连接`
http的长连接：
HTTP也可以建立长连接的，使用`Connection:keep-alive`，`HTTP 1.1默认进行持久连接（长连接）`

### HTTP1 和 HTTP1.1
#### Http1.1比Http1.0多了以下优点：
- 在同一个tcp的连接中可以传送`多个HTTP请求和响应`.
- 多个请求和响应可以重叠，多个请求和响应可以同时进行.
- `更加多的请求头和响应头`(比如HTTP1.0没有`host`的字段).
- 提供了`身份认证、状态管理和Cache缓存`等机制相关的请求头和响应头

### HTTP请求的GET与POST方式的区别
(1) get是从服务器`获取数据`,Post是向服务器`传送数据`,
(2) get是把参数数据队列加到提交表单的Action属性所指的URL中,值和表单内容各个字段一一对应,在`URL可以看到`,Post是把表单字段内容等放
于`html的header内一起传送到Action属性所指的URL地址.不可见`.
(3) get方式,服务端可以用Requset.Query获取变量值.
  Post方式,服务器用requset.form获取提交数据.
(4) get`传输大小不可大于2KB`,Post无限制.
(5) `get不安全但效率高.Post安全`.
(6) 数据查询用get,其他用Post.

### Socket通信模型的使用，AIO和NIO。
`同步阻塞的BIO、同步非阻塞的NIO(jdk1.4+)、异步非阻塞的AIO(jdk1.7+)`
1、BIO(IO)是`一个连接一个线程`。每个线程亲自处理io并且一直等待io的完成
IO的局限：IO是面向流的，阻塞式的，串行的一个过程

2、NIO是`一个请求一个线程`。每个线程亲自处理io，但有另外的线程轮询检查是否io准备完毕，不必等待io完成，即客户端发送
的连接请求都会注册到`多路复用器`上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 NIO则是面向缓冲区的，非阻塞式的，
基于选择器的，`用一个线程来轮询监控多个数据传输通道`，哪个通道准备好了（即有了一组可以处理的数据），就处理哪个通道。

- Channel
相对于BIO的流，NIO抽象出了新的通道（Channel）作为输入输出的通道，并且提供了缓存（Buffer）的支持，在进行读操作时，需要使用Buffer
分配空间，然后将数据从Channel中读入Buffer中，对于Channel的写操作，也需要现将数据写入Buffer，然后将Buffer写入Channel中。
Channel和IO中的Stream(流)是差不多一个等级的。只不过Stream是单向的，譬如：InputStream, OutputStream。而Channel是双向的，
既可以用来进行读操作，又可以用来进行写操作，NIO中的Channel的主要实现有：FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel；通过看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。
- Buffer
NIO中的关键Buffer实现有：ByteBuffer、CharBuffer、DoubleBuffer、 FloatBuffer、IntBuffer、 LongBuffer,、ShortBuffer，分别对应
基本数据类型: byte、char、double、 float、int、 long、 short。当然NIO中还有MappedByteBuffer, HeapByteBuffer, DirectByteBuffer等这里先不具体陈述其用法细节。
- Selector
Selector 是NIO相对于BIO实现多路复用的基础，Selector 运行单线程处理多个 Channel，如果你的应用打开了多个通道，但每个连接的流量都很低，
使用 Selector 就会很方便。例如在一个聊天服务器中。要使用 Selector , 得向 Selector 注册 Channel，然后调用它的 select() 方法。
这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新的连接进来、数据接收等。

3、AIO(Asynchronous io、NIO.2)是`一个有效请求一个线程`。客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，
每个线程不必亲自处理io，而是`委派os来处理`，并且也不需要等待io完成了，如果完成后，os会通知的。 

BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引入多线程，每个连接一个单独的线程；而`NIO则是使用单线程或者只使用少量的多线程`，
`每个连接共用一个线程`。
NIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线
程就可以搞定，当这个线程 中的`多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理`，也就是一个请求一个线
程模式。
 在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，
当并发上来的话，还是会有BIO一样的问题。
在NIO处理中可以进一步的进化，`在后端资源中可以实现资源池或者队列`，当请求来的话，开启的线程把请 求和请求数据传送给后端资源
池或者队列里面就返回，并且在全局的地方保持住这个现场(哪个连接的哪个请求等)，这样前面的线程还是可以去接受其他的请求， 而后
端的应用的处理只需要执行队列里面的就可以了，这样请求处理和后端应用是异步的.当后端处理完，到全局地方得到现场，产生响应，这
个就实现了异步处理。

### BIO、NIO、AIO适用场景 
BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 
NIO方式适用于`连接数目多且连接比较短（轻操作）的架构`，比如`聊天服务器`，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 
AIO方式使用于`连接数目多且连接比较长（重操作）的架构`，比如`相册服务器`，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 

4. socket框架netty的使用，以及NIO的实现原理，为什么是异步非阻塞。
3个NIO框架：Mina， Netty， Grizzly
`Netty是一个NIO客户端/服务器框架，支持快速、简单地开发网络应用`，如协议服务器和客户端。它极大简化了网络编程，如TCP和UDP套接字服务器

### 阻塞 非阻塞 同步 异步
#### 老张煮水
1. 老张把水壶放到火上，立等水开。（`同步阻塞`）老张觉得自己有点傻
2. 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（select`同步非阻塞`）老张还是觉得自己有点傻，于是变高端了，买了把会响笛的
那种水壶。水开之后，能大声发出嘀~~~~的噪音。
3. 老张把响水壶放到火上，立等水开。（`异步阻塞`）老张觉得这样傻等意义不大
4. 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（`异步非阻塞`）老张觉得自己聪明了。

阻塞，线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行

#### 非阻塞
非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的；
我们把一个SOCKET接口设置为非阻塞就是告诉内核，`当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误`。这样我们的I/O操作函数
将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。


#### 阻塞和同步的区别
有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回
而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理
各种各样的消息。


### OSI 7层
OSI中的层            功能                                                                    TCP/IP协议族
应用层               应用程序，文件传输、电子邮件、文件服务、虚拟终端，用于通信的                 HTTP、SNMP(简单网络管理协议 Simple Network Manage Protocol)、FTP、SMTP、POP3、DNS、Telnet、SOAP
表示层               `数据格式化、代码转换、数据加密 `，我们语言和机器语言的转化，                        
                        表现出来就是各种各样的文件拓展名。                                     没有协议  
会话层               解除或建立与别的接口的联系，`建立、控制、维护会话`，
                        NFS (Network FileSystem)、RPC (Remote Procedure Call)工作在这层       没有协议  
传输层               `负责分割、组合数据，实现端到端的逻辑连接。`分割成`段(Segment)`
                        三次握手、面向连接或非面向连接、流控(Flow Control)都是在这层            TCP、UDP  

网络层               `负责管理网络地址，定位设备，决定路由。`IP地址和路由器就是工作在这一层。
                        上层的数据段在这一层被分割，封装后叫做包`(Packet)`，包有两种，一种叫做       IP、ICMP（Internet Control Message Protocol网际控制信息协议 `ping使用`）、
                        用户数据包(Data Packets)，是上层传下来的用户数据；另一种叫做路由更新包     RIP(Router Information Protocol 路由信息协议)、OSPF(开放最短路径优先协议)、IGMP(内部网关路由协议)  
                        (Route update packets)，是直接由路由器发出来的，用来和其他路由器进行
                        路由信息的交换。                                                      
                                                                                                
数据链路层           物理传输 `错误检测功能` CRC校验、错误通知, MAC地址和交换机都工作在这层，
                        上层传下来的包在这层被分割后封装成`帧(Frame)`                            ARP(地址解析协议)、RARP(逆向地址解析协议)、PPP(点对点协议)
物理层               以二进制数据形式在物理媒体上传输数据                                       ISO2110、IEEE802、IEEE802.2  

RPC(远程过程调度协议) 和 SSL(安全套接字层协议) 在传输层和网络层中间


循环冗余校验码（Cyclic Redundancy Check）

具体说:
网线，集线器(Hub)－－－－物理层
网卡，网桥、二层交换机(Switch)－－－－数据链路
路由器(Router)－－－－－网络层

SNMP:(Simple Network Management Protocol)简单网络管理协议, 是专门设计用于在 IP 网络管理网络节点（服务器、工作站、路由器、交换机
及HUBS等）的一种标准协议，它是一种应用层协议。 SNMP 使网络管理员能够管理网络效能，发现并解决网络问题以及规划网络增长。通过 SNMP 接收
随机消息（及事件报告）网络管理系统获知网络出现问题。
SNMP是一系列协议组和规范，它们提供了一种从网络上的设备中收集网络管理信息的方法，也为设备向网络管理工作站报告问题和错误提供了一种方法。
SNMP基于传输层UDP用户数据报协议，在管理者和被管理设备（确切的说是agent）之前传递信息。
SNMP管理包括下面三个部分：
1.MIB管理信息库
2.SMI管理信息的结构和标识（也称管理信息接口SMI）
3.SNMP简单网络管理协议

### TCP/IP四层
应用层
传输层
网络层
链路层

#### 两主机数据传送
两主机通信的过程，从发送者（以下简称A）到接收者（以下简称B），属于从7层（应用层）->1层（物理层）封装，然后传输到远端，
再从1层（物理层）->7层（应用层）解封装的过程。
- 局域网(LAN)
假设两端的通信实体在一个局域网内，其实传输的数据包去到`交换机`时，交换机拆开二层`帧头`，再查自身的MAC地址表，发现表里面有对应的MAC地址，
然后对应的对口是哪个，接着就把帧发送到该端口转发出去，它的任务就完成了。根本不需要到达网络层的意思是，根本都不需要拆卡3层的IP包头来读取里面的信息。
- 广域网(WAN)
由于A、B两通信实体跨域广域网，所以光靠MAC地址表，肯定是查不到的，这时候路由器会把`IP包头`也拆开，读取目的IP地址，再查`路由表`，就知道往
哪个端口发出去了。然后层层转发，就可以达到目的地了，接下来就和局域网的一样了。

### 分布式通信的几种方式 （EJB、RMI、RPC、JMS、web service杂谈）
#### Linux笔试题12．简述网络文件系统NFS，并说明其作用。
参考答案：
网络文件系统是应用层的一种应用服务，它主要应用于`Linux`和Linux系统、Linux和`Unix`系统之间的`文件或目录的共享`。对于用户而言可以通过
NFS方便的访问远地的文件系统，使之成为本地文件系统的一部分。采用NFS之后`省去了登录的过程，方便了用户访问系统资源`。

#### 什么是 NFS (Network FileSystem)
最大的功能就是可以透过网络，让不同的机器、不同的操作系统、可以彼此分享个别的档案 (share files)。
远程主机的目录就好像是自己的一个磁盘分区槽一样 (partition)！使用上面相当的便利！
 NFS 的功能所对应的端口才没有固定住， 而是`随机取用一些未被使用的小于 1024 的端口来作为传输之用`。
因为预设 NFS 用来传输的埠口是随机选择小于 1024 以下的埠口来使用的。咦！那客户端怎么知道你服务器端使用那个埠口啊？此时就得要 远程过程调用 (Remote Procedure Call, RPC) 的协定来辅助啦！
#### 什么是 RPC (Remote Procedure Call)
RPC 最主要的功能就是在`指定每个 NFS 功能所对应的 port number` ，并且`回报给客户端`，让客户端可以连结到正确的埠口上去。 那 RPC 又是
如何知道每个 NFS 的埠口呢？这是因为当服务器在启动 NFS 时会随机取用数个埠口，并主动的向 RPC 注册，因此 RPC 可以知道每个埠口对应的 
NFS 功能，然后 RPC 又是固定使用 port 111 来监听客户端的需求并回报客户端正确的埠口， 所以当然可以让 NFS 的启动更为轻松愉快了！

RPC使用C/S方式，`采用http协议,`发送请求到服务器，等待服务器返回结果。`优点是跨语言跨平台，C端、S端有更大的独立性，
缺点是不支持对象，不支持异步调用，无法在编译器检查错误，只能在运行期检查。`
它是早期的支持分布式一种，缺点rpc是面向过程的远程调用，不支持面向对象，所以现在用的人就少了。不支持异步调用

### RPC 框架 Dubbo
服务自动注册发现依赖于注册中心的支持，consumer与provider通过注册中心获取各自地址后直接通信。目前考拉使用Zookeeper作为注册中心
然而在容错降级与短路降级之间，Dubbo缺乏一种在容错与短路间切换的机制，即自动熔断。自动熔断要达到的效果是：当接口偶然报错时执行容错返回
备用数据，而当接口持续大量报错时能自动在消费端对接口调用短路直接返回备用数据，之后持续监测接口可用性，接口恢复后自动恢复调用。这样能
最大限度减少接口异常对消费方的影响，同时也减轻本就处于异常状态的提供端负载。

#### JMS(Java Message Service)
`jms是在各个java类（包括ejb类）之间传递消息的中间件，`好比给我们送信的邮递员，在各个人之间收发信件。
支持两种消息模型P2P和pub/stub，即`点对点和发布订阅模型。`
传输的是一种消息移植机制，将消息从一个客户机移动到另一个终端。
优点：`支持异步通信、消息produce和recept松耦合。`
#### web service(架构课讲的那个，但是那里只讲了服务注册和发布)
Web Service提供的服务是基于web容器的，底层使用http协议，类似一个远程的服务提供者，比如天气预报服务，对各地客户端提供
天气预报，是一种请求应答的机制，是跨系统跨平台的。就是通过一个servlet，提供服务出去。
首先客户端从服务器的到WebService的WSDL，同时在客户端声称一个代理类(Proxy Class) 这个代理类负责与WebService服务器进行
Request 和Response 当一个数据（XML格式的）被封装成SOAP格式的数据流发送到服务器端的时候，就会生成一个进程对象并且把接收
到这个Request的SOAP(Simple Object Access Protocol 简单对象访问协议)包进行解 析，然后对事物进行处理，处理结束以后再对这个计算结果进行SOAP包装，然后把这个包作为一个
Response发送给客户端的代理类(Proxy Class)，同样地，这个代理类也对这个SOAP包进行解析处理，继而进行后续操作。
这就是WebService的一个运行过程。
####### Web Service大体上分为5个层次: 
1. Http传输信道 
2. XML的数据格式 
3. SOAP封装格式 
4. WSDL的描述方式 
5. `UDDI UDDI是一种目录服务，企业可以使用它对Webservices进行注册和搜索`
服务提供者通过WSDL向注册中心描述自身提供的服务接口属性，注册中心使用UDDI发布提供者提供的服务，服务器请求者从注册中心检索到
服务信息后，通过 SOAP 和服务提供者通信，使用相关服务。
缺点：
1. 臃肿的注册和发现机制
2. 低效的 XML序列化手段
3. 开销相对较高的HTTP远程通信
4. 复杂的部署和维护手段


### http中，Get和Post的区别
- GET 被强制服务器支持
- 浏览器对URL的长度有限制，所以GET请求不能代替POST请求发送大量数据
- GET请求发送数据更小
- GET请求是安全的， 这里的安全指的是在规范的定义下，Get操作不会修改服务器的数据
- GET请求是幂等的
- POST请求不能被缓存
- POST请求相对GET请求是「安全」的，这里所有的「安全」是相对的，因为GET请求有时候会直接反应在浏览器的地址栏，而现在的浏览器大多会记住曾经输入过的URL

##### url编码
其实url编码就是一个字符ascii码的十六进制。不过稍微有些变动，需要在前面加上“%”。比如“\”，它的ascii码是92，92的十六进制是5c，
所以“\”的url编码就是%5c。那么汉字的url编码呢？很简单，看例子：“胡”的ascii码是-17670，十六进制是BAFA，url编码是“%BA%FA”。
空格 URL中的空格可以用+号或者编码%20 

##### BASE64编码
Base64编码要求把3个8位字节（3*8=24）转化为4个6位的字节（4*6=24），之后在6位的前面补两个0，形成8位一个字节的形式。 如果剩下的字符
不足3个字节，则用0填充，输出字符使用‘=’，因此编码后输出的文本末尾可能会出现1或2个‘=’。

###### 加密算法种类
按照加密的方式我们可以将加密算法大体分成一下三种：
* 对称加密算法 DES算法，3DES算法
* 非对称加密算法 RSA
* 经典哈希算法 MD2、MD4、MD5 和 *


### 说说http,tcp,udp和Socket之间关系和区别
- HTTP协议是建立在请求/响应模型上的
- TCP/IP是个协议族，可分为三个层次：网络层、传输层和应用层
- Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口

### Tcp 和 Udp区别
Tcp(Transmission Control Protocol)全称为传输控制协议。这种协议可以提供`面向连接的、可靠的、点到点的通信`。
Udp(User Datagram Protocol)全称为用户数据报协议，它可以提供非连接的不可靠的`点到多点`的通信。

-                               TCP                                                    UDP
可靠性                           可靠                                                   不可靠
连接性                           面向连接                                               无连接
报文                             面向`字节流`                                           `面向报文`(保留报文的边界)
效率                             传输效率低                                             传输效率高
双工性                           全双工                                                 一对一、一对多、多对一、多对多        
流量控制                         有(滑动窗口)                                            无
拥塞控制                         有(慢开始、拥塞避免、快重传、快恢复)                      无
传输速度                         慢                                                      快
应用场合                         对效率要求低，对`准确性要求高`；或者要求`有连接的`场景      对效率要求高，对准确性要求低的场景
应用示例                        TCP 一般用于文件传输(FTP Http)，发送或接受邮件              UDP 一般用于即时通信(QQ聊天) 在线视频 网络语音电话     
                               (SMTP POP IMAP) 远程登陆(Telnet SSH)
### TCP和UDP区别？
1. TCP协议在传送数据段的时候要给段标号；UDP协议不
2. TCP协议可靠；UDP协议不可靠ip和port封装在datagram数据包中，自寻址。
3. TCP协议是面向连接；UDP协议采用无连接
4. TCP协议负载较高，采用虚电路；UDP采用无连接
5. TCP协议的发送方要确认接收方是否收到数据段（3次握手协议）
6. TCP协议采用窗口技术和流控制

### TCP 如何保证可靠性
实现TCP的可靠传输有以下机制：
1，校验和（校验数据是否损坏）；
2，定时器（分组丢失则重传）；
3，序号（用于检测丢失的分组和冗余的分组）；
4，确认（接收方告知发送方正确接收分组以及期望的下一个分组）；
5，否定确认（接收方通知发送方未被正确接收的分组）；
6，窗口和流水线（用于增加信道的吞吐量）。

##### 校验和
 在发送数据时，为了计算数据包的校验和。应该按如下步骤：
（1）把校验和字段置为0；
（2）把需校验的数据看成以16位为单位的数字组成，依次进行二进制反码求和；
（3）把得到的结果存入校验和字段中。
在接收数据时，计算数据包的校验和相对简单，按如下步骤：
（1）把首部看成以16位为单位的数字组成，依次进行二进制反码求和，包括校验和字段；
（2）检查计算出的校验和的结果是否为0；
（3）如果等于0，说明被整除，校验是和正确。否则，校验和就是错误的，协议栈要抛弃这个数据包。
UDP和TCP校验和不仅覆盖整个报文，而且还有12字节的IP伪首部，包括源IP地址(4字节)、目的IP地址(4字节)、协议(2字节，第一字节补0)
和TCP/UDP包长(2字节)。另外UDP、TCP数据报的长度可以为奇数字节，所以在计算校验和时需要在最后增加填充字节0（注意，填充字节只是为了
计算校验和，可以不被传送）。


#### 如何理解端到端通信 
TCP 和 UDP 都是端到端通信，端为端口识别进程。点对点通信为主机和另一个主机之间通信。　　
OSI七层模型中的物理层、数据链路层和网络层是面向网络通信的低三层，为网络环境中的主机提供点对点通信服务。这种通信是直接相连的节点对等
实体的通信，它只提供一台机器到另一台机器之间的通信，不会涉及到程序或进程的概念。同时点到点通信并不能保证数据传输的可靠性，也不能说明
源主机与目的主机之间是哪两个进程在通信。　　端到端通信建立在点到点通信的基础上，是经点到点通信更高一级的通信方式，完成应用程序（进程）
之间的通信。OSI参考模型中的传输层功能的裨是最终完成端到端的可靠连接。“端”是指用户应用程序的“端口”，端口号标识了应用层中不同的进程，
多个进程的数据传递通过不同的端口完成。


### 滑动窗口协议
简单解释下，`发送和接受方都会维护一个数据帧的序列，这个序列被称作窗口`。发送方的窗口大小由接受方确定，目的在于控制发送速度，
以免接受方的缓存不够大，而导致溢出，同时控制流量也可以避免网络拥塞。
发送方都维持了一个连续的允许发送的帧的序号，称为发送窗口；同时，接收方也维持了一个连续的允许接收的帧的序号，称为接收窗口。发送窗口和接收窗口的序号的上下界不一定要一样，甚至大小也可以不同。
拥塞滑动窗口的大小可以控制发送端发送窗口的大小，这样就可以`控制发送端的发送流量大小。`

##### 糊涂窗口综合症
当发送端应用进程产生数据很慢、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使应用进程间传送的报文段很小，特别是有效载
荷很小。 极端情况下，有效载荷可能只有1个字节；而传输开销有40字节(20字节的IP头+20字节的TCP头) 这种现象就叫糊涂窗口综合症。

对于这种`糊涂窗口综合症，即应用程序消耗数据比到达的慢`，有两种建议的解决方法。
1.Clark解决方法
Clark解决方法是只要有数据到达就发送确认，但宣布的窗口大小为零，直到或者缓存空间已能放入具有最大长度的报文段，或者缓存空间的一半已经空了。
2.延迟确认
这表示当一个报文段到达时并不立即发送确认。接收端在确认收到的报文段之前一直等待，直到入缓存有足够的空间为止。延迟的确认防止了发送端的
TCP滑动其窗口。当发送端的TCP发送完其数据后，它就停下来了。这样就防止了这种症状。迟延的确认还有另一个优点：它减少了通信量。接收端不
需要确认每一个报文段。但它也有一个缺点，就是迟延的确认有可能迫使发送端重传其未被确认的报文段。可以用协议来平衡这个优点和缺点，例如现在定义了确认的延迟不能超过500毫秒。[


#### 滑动窗口也称通告窗口
滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。
TCP的滑动窗口解决了端到端的流量控制问题，允许接受方对传输进行限制，直到它拥有足够的缓冲空间来容纳更多的数据。
#### 拥塞窗口
拥塞窗口也看做是发送端用来进行流量控制的窗口。
但是，实际上，TCP还必须应付互联网中的拥塞现象。拥塞是指一个或者多个交换点的数据报超载而导致时延剧烈增加的现象。为了控制拥塞，
TCP使用了第二个窗口限制，即拥塞窗口限制。对于拥塞窗口大小的限制采用慢开始和乘法减小两种技术。
乘法减小的拥塞避免策略：一旦发现报文段丢失，就把拥塞窗口的大小减半（直到减至最小的窗口，窗口中应至少包含一个报文段）。
慢开始恢复：拥塞窗口随着一个确认的到达，拥塞窗口的大小每次增加一个报文段。

我是这么理解的滑动窗口和拥塞窗口都控制了流量，只是发送方有慢启动、快重传、快恢复的方式来避免拥塞。

#### 慢开始原理
（1）在主机刚刚开始发送报文段时可先将拥塞窗口 cwnd 设置为一个最大报文段 MSS 的数值。
（2）在每收到一个对新的报文段的确认后，将拥塞窗口增加至多一个 MSS 的数值。
（3）用这样的方法`逐步增大发送端的拥塞窗口` cwnd，可以使分组注入到网络的速率更加合理。
#### 快重传
发送端只要一连收到三个重复的 ACK 即可断定有分组丢失了，就应立即重传丢失的报文段而不必继续等待为该报文段设置的重传计时器的超时
#### 快恢复
(1) 当发送端收到连续三个重复的 ACK 时，就重新设置慢开始门限 ssthresh。
(2) 与慢开始不同之处是 swnd 不是设置为 1，而是设置为 ssthresh + 3 * MSS。 
(3) 若收到的重复的 ACK 为 n 个（n > 3），则将 cwnd 设置为 ssthresh + n * MSS。
(4) 若发送窗口值还容许发送报文段，就按拥塞避免算法继续发送报文段。
(5) 若收到了确认新的报文段的 ACK，就将 swnd 缩小到 ssthresh。

#### 拥塞避免算法是一种处理丢失分组的方法。
该算法假定由于分组受到损坏引起的丢失是非常少的（远小于1%），因此分组丢失就意味着在源主机和目的主机之间的某处网络上发生了拥塞。有两种分组丢失的指示：发生超时
和接收到重复的确认。如果使用超时作为拥塞指示，则需要使用一个好的RTT算法。
拥塞避免算法和慢启动算法是两个目的不同、独立的算法。

#### connect会阻塞，怎么解决?(必考必问)
最通常的方法最有效的是加定时器；也可以采用非阻塞模式。
设置非阻塞，返回之后用select检测状态
#### 如果select返回可读，结果只读到0字节，什么情况？
某个套接字集合中没有准备好，可能会select内存用FD_CLR清该位为0；
#### keepalive是什么东东？如何使用？
设置Keepalive参数，检测已中断的客户连接
在TCP中有一个Keep-alive的机制可以检测死连接，原理很简单，TCP会在空闲了一定时间后发送数据给对方：
1.如果主机可达，对方就会响应ACK应答，就认为是存活的。
2.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
3.如果可达，但应用程序崩溃，对方就发FIN消息。
4.如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。这个时间就是默认
的二个小时。
#### TCP (20字节) 和 UDP (8字节) 报文头部
##### TCP 头部
源端口和目的端口:　　各占 2 字节.端口是传输层与应用层的服务接口.传输层的复用和分用功能都要通过端口才能实现
序号:　　 Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。
确认号:　　 Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。
数据偏移/首部长度:　　占 4 位,它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远.“数据偏移”的单位是 32 位字(以 4 字节为计算单位)
保留:　　占 6 位,保留为今后使用,但目前应置为 0
紧急URG:　　当 URG=1 时,表明紧急指针字段有效.它告诉系统此报文段中有紧急数据,应尽快传送(相当于高优先级的数据)
确认ACK:　　只有当 ACK=1 时确认号字段才有效.当 ACK=0 时,确认号无效。   不要将确认序号Ack与标志位中的ACK搞混了。
PSH(PuSH):　　接收 TCP 收到 PSH = 1 的报文段,就尽快地交付接收应用进程,而不再等到整个缓存都填满了后再向上交付
RST (ReSeT):　　当 RST=1 时,表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因）,必须释放连接,然后再重新建立运输连接
同步 SYN:　　同步 SYN = 1 表示这是一个连接请求或连接接受报文
终止 FIN:　　用来释放一个连接.FIN=1 表明此报文段的发送端的数据已发送完毕,并要求释放运输连接
检验和:　　占 2 字节.检验和字段检验的范围包括首部和数据这两部分.在计算检验和时,要在 TCP 报文段的前面加上 12 字节的伪首部
紧急指针:　　占 16 位,指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）
选项:　　长度可变.TCP 最初只规定了一种选项,即最大报文段长度 MSS.MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节.” MSS(Maximum Segment Size)是 TCP 报文段中的数据字段的最大长度.数据字段加上 TCP 首部才等于整个的 TCP 报文段
填充:　　这是为了使整个首部长度是 4 字节的整数倍

##### UDP 头部
2字节源端口字段
2字节节的端口字段
2字节长度字段
2字节校验和字段

TCP可能发送100个“包”，而接收到50个“包”，不是丢“包”了，而是每次接受的“包”都比发送的多，其实TCP并没有包的概念。例如，每次发10个字节，可能读得时候一次读了20个字节。TCP是一种流模式的协议，在接收到的缓存中按照发送的包得顺序自动按照顺序拼接好，因为数据基本来自同一个主机，而且是按照顺序发送过来的

##### 1)tcp三次握手的过程，accept发生在三次握手哪个阶段？
三次握手之后
##### 2）Tcp流， udp的数据报，之间有什么区别，为什么TCP要叫做数据流？
流无边界,数据报有边界.TCP是先进先出的,并且可靠.


### TCP粘包
粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。1个包尾相粘下一个包的头部
在socket网络程序中，TCP和UDP分别是面向连接和非面向连接的。因此TCP的socket编程，收发两端（客户端和服务器端）都要有成对的socket，
因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小、数据量小的数据，合并成一个大的
数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。

对于UDP，不会使用块的合并优化算法，这样，实际上目前认为，是由于UDP支持的是一对多的模式，所以接收端的skbuff(套接字缓冲区）采用了
链式结构来记录每一个到达的UDP包，在每个UDP包中就有了消息头（消息来源地址，端口等信息），这样，对于接收端来说，就容易进行区分处理了。
所以UDP不会出现粘包问题。
#### 粘包、拆包解决办法
通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：
1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。



### 网络中的进程通信：
- 网络层的“`ip地址`”可以唯一标识网络中的`主机`，
- 传输层的“`协议+端口`”可以唯一标识主机中的`应用程序（进程）`。  比如找到了个 tomcat、nginx
- 这样利用三元组（ip地址，协议，端口）就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互。


### 子网、子网掩码、主机
参考博客 [IP地址子网掩码]
#### A类，B类，C类
概念	        特征	                                    网络范围	                    默认掩码
A类地址	    第1个8位中的第1位始终为0	                0-127.x.x.x	                255.0.0.0/8
B类地址	    第1个8位中的第1、2位始终为10	            128-191.x.x.x	            255.255.0.0/16
C类地址	    第1个8位中的第1、2、3位始终为110	        192-y.x.x.x	                255.255.255.0/24
其中127.x.x.x段地址空间是被保留的回环地址
IP地址包含 网络地址+主机地址，即IP地址=网络地址+主机地址
子网掩码不能单独存在，它必须结合IP地址一起使用。子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。 
- 通过子网掩码，就可以判断两个IP在不在一个局域网内部。
- 子网掩码可以看出有多少位是网络号，有多少位是主机号


#### 根据IP地址和子网掩码求 网络地址 和 广播地址

网络地址+1即为第一个主机地址，广播地址-1即为最后一个主机地址， 
由此可以看出地址范围是： 网络地址+1 至 广播地址-1
主机的数量=2^二进制位数的主机-2
减2是因为主机不包括网络地址和广播地址。
示例 
一个主机的IP地址是202.112.14.137，掩码是255.255.255.224，要求计算这个主机所在网络的网络地址和广播地址
根据子网掩码可以分割网络号+主机号
255.255.255.224 转二进制：
11111111 11111111 11111111 11100000
网络号有27位，主机号有5位
网络地址就是：把IP地址转成二进制和子网掩码进行与运算  `IP 地址后几位全为0`

11001010 01110000 00001110 10001001
IP地址&子网掩码
11001010 01110000 00001110 10001001
11111111 11111111 11111111 11100000
------------------------------------------------------
11001010 01110000 00001110 10000000

即：202.112.14.128
计算广播地址
广播地址：网络地址的主机位全部变成1 ，10011111 即159 即：202.112.14.159
主机数
主机号有5位，那么这个地址中，就只能有25−2=30个主机
`因为其中全0作为网络地址，全1作为广播地址`
根据每个网络的主机数量进行子网地址的规划和计算子网掩码
这也可按上述原则进行计算。
比如一个子网有10台主机，那么对于这个子网需要的IP地址是 
10＋1＋1＋1＝13 
注意：加的第一个1是指这个网络连接时所需的网关地址，接着的两个1分别是指网络地址和广播地址。 
因为13小于16（16等于2的4次方），所以主机位为4位。
而 256－16＝240 所以该子网掩码为255.255.255.240。
如果一个子网有14台主机，不少人常犯的错误是：依然分配具有16个地址空间的子网，而忘记了给网关分配地址。这样就错误了，因为： 
14＋1＋1＋1＝17 
17.大于16，所以我们只能分配具有32个地址（32等于2的5次方）空间的子网。这时子网掩码为：255.255.255.224
#### 主机的数量
206.110.4.0/18被划分成16个子网，每个子网掩码？
（划分成16个子网，根据子网掩码/18就表示有18个1，就要从的IP地址的主机位借4位来用作网络位！）
子网掩码是255.255.252.0
每个子网可以容纳的主机数是1024台。
下面我来给你详细解答：
206.110.1.0 /18 由最后的那个/18，我们可以知道这个IP已经规定了它的网络位是18位，它默认的子网掩码就是11111111.11111111.11 | 000000.00000000(其中1代表网络位,0代表主机位)
可以看出我们可以操作的位数就是后面的14个0，也就是说我们可以在地面划分出几位作为子网的网络位，进而来划分子网。要求是切分成16个子网，
我们知道2的4次方刚好等于16，这就说明子网网络位的位数是4位，那14-4=10就是子网的主机位。所以上面我写的那串二进制就可以变成：
11111111.11111111.111111 | 00.00000000(其中1代表网络位,0代表主机位)
ip段/数字-如192.168.0.1/24是什么意思?
后面这个数字标示了我们的网络号的位数，也就是子网掩码中前多少号为1
129.168.1.1 /24 这个24就是告诉我们网络号是24位
也就相当于告诉我们了
子网掩码是：11111111 11111111 11111111 00000000
即：255.255.255.0

####### 如果主机的IP地址是172.18.70.21/29，与该主机属于同一子网的有（）
A 172.18.70.20
B 172.18.70.18
C 172.18.70.24
D 172.18.70.15
选 A B
把21写成二进制的形式，因为有29位子网掩码，所以只留最后三位用来作为主机号，另外由于主机号不能为全零或者全一，所以，只能取001-110这几种，
算一下应该范围是17-22，所以选AB
同属于一个子网，则最后8位必须满足00010xxx


#### Http 请求头(Request Header) 响应头(Response Header) 字段

##### Request Headers
Accept:*/*
Accept-Encoding:gzip, deflate
Accept-Language:zh-CN,zh;q=0.8
Connection:keep-alive
Content-Length:297
Content-Type:application/x-www-form-urlencoded; charset=UTF-8
Cookie:__smScrollBoxOptOut=true; _ga=GA1.2.845410506.1486610788; __utma=213602508.845410506.1486610788.1502869057.1502896422.39; __utmc=213602508; __utmz=213602508.1502896425.39.37.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); Hm_lvt_5101210b73a0e033d1509b3e487c929c=1502805825,1502869059,1502896424,1502896428; Hm_lpvt_5101210b73a0e033d1509b3e487c929c=1502896428; infoq_hab=oooy; __smToken=aRCxOMxFjjXA3v6RwWdEeYz6; JSESSIONID=2BDFCCE5BA92D68AEDD96CFDF6B70785; UserCookie=bcQxKCTrJZU6d66ckNuL8MqebzpkJccI
Host:www.infoq.com
Origin:http://www.infoq.com
Referer:http://www.infoq.com/cn/articles/key-steps-and-likely-problems-of-split-table
User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36

###### Response Header
Accept-Ranges:none
Access-Control-Allow-Credentials:true
Access-Control-Allow-Origin:https://www.infoq.com
`Cache-Control:no-cache`
`Connection:close`
Content-Length:1869
Content-Type:application/json;charset=utf-8
Date:Thu, 17 Aug 2017 02:02:01 GMT
Server:Apache
Sniply-Options:BLOCK
Vary:Accept-Encoding,User-Agent



### HTTP有哪些请求
- HTTP/1.0
这个版本是第一个在HTTP通讯中指定版本号的协议版本，HTTP/1.0至今仍被广泛采用，特别是在代理服务器中。
`HTTP/1.0支持：GET、POST、HEAD`三种HTTP请求方法。
- HTTP/1.1
HTTP/1.1是当前正在使用的版本。该版本默认采用持久连接，并能很好地配合代理服务器工作。还支持以管道方式同时发送多个请求，以便降低线路
负载，提高传输速度。
`HTTP/1.1新增了：OPTIONS、PUT、DELETE、TRACE、CONNECT`五种HTTP请求方法。
- HTTP/2
这个版本是最新发布的版本，于今年5月（2015年5月）做HTTP标准正式发布。HTTP/2通过支持请求与相应的多路重用来减少延迟，通过压缩HTTP头
字段将协议开销降到最低，同时增加了对请求优先级和服务器端推送的支持。

- GET
GET请求会显示请求指定的资源。一般来说GET方法应该只用于数据的读取，而不应当用于会产生副作用的非幂等的操作中。
GET会方法请求指定的页面信息，并返回响应主体，GET被认为是不安全的方法，因为GET方法会被网络蜘蛛等任意的访问。
- HEAD
HEAD方法与GET方法一样，都是向服务器发出指定资源的请求。但是，`服务器在响应HEAD请求时不会回传资源的内容部分`，即：响应主体。这样，
我们可以不传输全部内容的情况下，就可以获取服务器的响应头信息。`HEAD方法常被用于客户端查看服务器的性能`。
- POST
POST请求会 向指定资源提交数据，请求服务器进行处理，如：表单数据提交、文件上传等，请求数据会被包含在请求体中。POST方法是非幂等的方法，
因为这个请求可能会创建新的资源或/和修改现有资源。
- PUT
`PUT请求会身向指定资源位置上传其最新内容`，PUT方法是幂等的方法。通过该方法客户端可以将指定资源的最新数据传送给服务器取代指定的资源的内容。
- DELETE
`DELETE请求用于请求服务器删除所请求URI`（统一资源标识符，Uniform Resource Identifier）所标识的资源。DELETE请求后指定资源会被删除，
DELETE方法也是幂等的。
- CONNECT
CONNECT方法是HTTP/1.1协议预留的，`能够将连接改为管道方式的代理服务器`。通常用于SSL加密服务器的链接与非加密的HTTP代理服务器的通信。
- OPTIONS
`OPTIONS请求与HEAD类似，一般也是用于客户端查看服务器的性能`。 这个方法会请求服务器返回该资源所支持的所有HTTP请求方法，该方法会用'*'来
代替资源名称，向服务器发送OPTIONS请求，可以测试服务器功能是否正常。JavaScript的XMLHttpRequest对象进行CORS跨域资源共享时，就是使用
OPTIONS方法发送嗅探请求，以判断是否有对指定资源的访问权限。 
- TRACE
`TRACE请求服务器回显其收到的请求信息，该方法主要用于HTTP请求的测试或诊断`。
HTTP/1.1之后增加的方法
在HTTP/1.1标准制定之后，又陆续扩展了一些方法。其中使用中较多的是	PATCH 方法：
- PATCH
PATCH方法出现的较晚，它在2010年的RFC 5789标准中被定义。PATCH请求与PUT请求类似，同样用于资源的更新。二者有以下两点不同：
但`PATCH一般用于资源的部分更新`，而`PUT一般用于资源的整体更新。`
当资源不存在时，PATCH会创建一个新的资源，而PUT只会对已在资源进行更新。



#### 大端字节序（big endian）和小端字节序（little endian）
- 大端字节序：高位字节在前，低位字节在后，这是人类读写数值的方法。
- 小端字节序：低位字节在前，高位字节在后，即以0x1122形式储存。

计算机电路先处理低位字节，效率比较高，因为`计算都是从低位开始的`。所以，计算机的内部处理都是小端字节序。
但是，人类还是习惯读写大端字节序。所以，`除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。`
字节序的处理，就是一句话："只有读取的时候，才必须区分字节序，其他情况都不用考虑。"
大端序是按照数字的书写顺序进行存储的，而小端序是颠倒书写顺序进行存储的。

### 腾讯加强版
参考[腾讯后台开发面试题]
#### 网络编程的一般步骤
对于TCP连接：
1.服务器端1）创建套接字create；2）绑定端口号bind；3）监听连接listen；4）接受连接请求accept，并返回新的套接字；5）用新返回的套接字recv/send；6）关闭套接字。
2.客户端1）创建套接字create; 2）发起建立连接请求connect; 3）发送/接收数据send/recv；4）关闭套接字。
TCP总结：
Server端：create -- bind -- listen--  accept--  recv/send-- close
Client端：create------- conncet------send/recv------close.

对于UDP连接：
1.服务器端:1）创建套接字create；2）绑定端口号bind；3）接收/发送消息recvfrom/sendto；4）关闭套接字。
2.客户端:1）创建套接字create；2）发送/接收消息sendto/recvfrom；3）关闭套接字.
UDP总结:
Server端：create----bind ----recvfrom/sendto----close
Client端：create----  sendto/recvfrom----close.

##### 关闭连接 close 和 shutdown 区别
- shutdown() 立即关闭socket;并可以用来唤醒等待线程;
- close() 不一定立即关闭socket`(如果有人引用, 要等到引用解除)`;不会唤醒等待线程。
close-----关闭本进程的socket id，但链接还是开着的，用这个socket id的其它进程还能用这个链接，能读或写这个socket id
shutdown--则破坏了socket 链接，读的时候可能侦探到EOF结束符，写的时候可能会收到一个SIGPIPE信号，这个信号可能直到
socket buffer被填充了才收到，shutdown还有一个关闭方式的参数，0 不能再读，1不能再写，2 读写都不能。


#### TCP的重发机制是怎么实现的？
1.`滑动窗口机制`，确立收发的边界，能让发送方知道已经发送了多少（已确认）、尚未确认的字节数、尚待发送的字节数；让接收方知道（已经确认收到的字节数）。
2.`选择重传`，用于对传输出错的序列进行重传。

#### TCP为什么不是两次连接？而是三次握手？
如果A与B两个进程通信，如果仅是两次连接。可能出现的一种情况就是：A发送完请报文以后，由于网络情况不好，出现了网络拥塞，即B延时很长时间
后收到报文，即此时A将此报文认定为失效的报文。B收到报文后，会向A发起连接。此时两次握手完毕，B会认为已经建立了连接可以通信，B会一直等到
A发送的连接请求，而A对失效的报文回复自然不会处理。依次会陷入B忙等的僵局，造成资源的浪费。

#### connect方法会阻塞，请问有什么方法可以避免其长时间阻塞？
可以考虑采用`异步传输机制`，同步传输与异步传输的主要区别在于同步传输中，如果调用recvfrom后会一致阻塞运行，从而导致调用线程暂停运行；
异步传输机制则不然，会立即返回。



#### 网络编程中设计并发服务器，使用多进程与多线程，请问有什么区别？
答案一:
1，进程：子进程是父进程的复制品。子进程获得父进程数据空间、堆和栈的复制品。
2，线程：相对与进程而言，线程是一个更加接近与执行体的概念，它可以与同进程的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。
两者都可以提高程序的并发度，提高程序运行效率和响应时间。
线程和进程在使用上各有优缺点：`线程执行开销小，但不利于资源管理和保护`；而进程正相反。同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移。
答案二:
根本区别就一点：用多进程每个进程有自己的`地址空间`(address space)，线程则共享地址空间。所有其它区别都是由此而来的：
1。速度：线程产生的速度快，`线程间的通讯快、切换快`等，因为他们在同一个地址空间内。
2。资源利用率：线程的资源利用率比较好也是因为他们在同一个地址空间内。
3。同步问题：线程使用公共变量/内存时需要使用同步机制还是因为他们在同一个地址空间内。

#### SNMP协议
简单网络管理协议——应用层协议.
包括5种数据包：Get-Request;Get-Next-Request; Set-Request, Get-Response; Trap;

### 五种I/O 模式
阻塞(默认IO模式)， 非阻塞(常用于管道)， I/O多路复用(IO多路复用的应用场景)， 信号I/O， 异步I/O  
五种I/O 模式：
【1】       阻塞I/O           (Linux下的I/O操作默认是阻塞I/O，即open和socket创建的I/O都是阻塞I/O)
【2】       非阻塞 I/O        (可以通过fcntl或者open时使用O_NONBLOCK参数，将fd设置为非阻塞的I/O)
【3】       I/O 多路复用     (I/O多路复用，通常需要非阻塞I/O配合使用) 事件驱动（在Linux下可以使用select/poll/epoll）
【4】       信号驱动 I/O    (SIGIO)
【5】        异步 I/O


### Http 状态码
- 301 VS 302
301，302 都是HTTP状态的编码，都代表着某个URL发生了转移，不同之处在于： 
301 redirect: 301 代表永久性转移(Permanently Moved)。
302 redirect: 302 代表暂时性转移(Temporarily Moved )。 
2.1.对于用户
301，302对用户来说没有区别，他们看到效果只是一个跳转，浏览器中旧的URL变成了新的URL。页面跳到了这个新的url指向的地方。
2.2.对于引擎及站长
个不道德的人在他自己的网址A做一个302重定向到你的网址B，出于某种原因， Google搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的
网址B上的内容，这种情况就叫做`网址URL劫持`。你辛辛苦苦所写的内容就这样被别人偷走了。
- 304  Not Modified 
客户端是怎么知道这些内容没有更新的呢？其实这并不是客户端的事情，而是你服务器的事情，大家都知道服务器可以设置缓存机制，这个功能是为
了提高网站的访问速度，当你发出一个GET请求的时候服务器会从缓存中调用你要访问的内容，这个时候服务器就可以判断这个页面是不是更新过了，
如果没有更新过那么他会给你返回一个304状态码。
- 503 VS 404
HTTP 503 错误 – 服务不可用 (Service unavailable)
503是一种HTTP状态码。英文名503 Service Unavailable与404（404 Not Found)是同属一种网页状态出错码。前者是服务器出错的一种返回状态，
后者是网页程序没有相关的结果后返回的一种状态，需要优化网站的时候通常需要制作404出错页以便网站整体优化。

#### 四种常见的 POST 提交数据方式
- application/x-www-form-urlencoded
这应该是最常见的 POST 提交数据的方式了。浏览器的原生 <form> 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 
方式提交数据。请求类似于下面这样（无关的请求头在本文中都省略掉了）：
BASH
POST http://www.example.com HTTP/1.1
Content-Type: application/x-www-form-urlencoded;charset=utf-8

title=test&sub%5B%5D=1&sub%5B%5D=2&sub%5B%5D=3
首先，Content-Type 被指定为 application/x-www-form-urlencoded；其次，提交的数据按照 key1=val1&key2=val2 的方式进行编码，
key 和 val 都进行了 URL 转码。大部分服务端语言都对这种方式有很好的支持。

- `multipart/form-data`
这又是一个常见的 POST 数据提交的方式。我们使用`表单上传文件时` `image/png`，必须让 <form> 表单的 enctype 等于 multipart/form-data。直接来看一个请求示例：
BASH
POST http://www.example.com HTTP/1.1
Content-Type:multipart/form-data;

- application/json
可以方便的提交复杂的结构化数据，特别适合 RESTful 的接口

- text/xml
它是一种使用 HTTP 作为传输协议，XML 作为编码方式的远程调用规范。

#### 从输入URL到页面加载发生了什么
总体来说分为以下几个过程:
- 最开始查自己的host文件
- DNS解析
递归和迭代查询的过程
比如输入www.google.com，先向本地域名服务器 -> 根域名服务器 -> 本地域名服务器 -> 顶级域名服务器 -> 本地域名服务器 -> google.com域名服务器，查到了ip 
- TCP连接
- 发送HTTP请求
- 服务器处理请求并返回HTTP报文
- 浏览器解析渲染页面
- 连接结束

### ARP工作原理　　　
- ARP工作过程　
1) 首先﹐每一台主机都会在 ARP Cache中建立一个 ARP表格﹐用来记录 IP地址和MAC地址的对应关系。这个 Table的每一条信息会根据自身的存活
时间递减而最终消失﹐以确保信息的真实性。
2) 当发送主机有一个封包要传送给目的主机并且获得目的主机的 IP 地址的时候﹐发送主机会先检查自己的 ARP表格中有没有与该 IP地址对应的MAC
地址。如果有﹐就直接使用此地址来传送封包﹔如果没有﹐则向网络发出一个 ARP Request广播封包﹐查询目的主机的MAC地址。这个封包会包含发送端
的 IP地址和MAC地址信息。
3) 这时﹐网络上所有的主机都会收到这个广播封包﹐会检查封包的 IP 栏位是否和自己的 IP 地址一致。如果不是则忽略﹔如果是则会先将发送端的
MAC地址和 IP资料更新到自己的 ARP表格去﹐如果已经有该 IP的对应﹐则用新的信息覆盖原来的﹔然后再回应一个 ARP Reply封包给对方﹐告知发送
主机关于自己的MAC地址﹔
4)当发送端接到 ARP Reply之后﹐也会更新自己的 ARP表格﹔然后就可以用此记录进行传送了。
5) 如果发送端没有得到 ARP Reply ﹐则宣告查询失败。

- ARP高速缓存
ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存，这个高速缓存放了最近Internet地址到硬件地址之间的映射记录，高速缓存中每一项的
生存时间一般为20分钟，起始时间从被创建时开始算起。我们可以通过arp -a或show arp来显示高速缓存中所有的内容

- ARP欺骗的防御
知道了ARP欺骗的方法和危害，我们给出一些初步的防御方法:
1)不要把安全信任关心建立在ip地址或者mac地址的基础上(RARP同样存在欺骗问题),理想的关系应该是ip+mac;
2)设置静态的mac->ip映射,不要让主机刷新设置好的arp转换表.
3)停止使用arp,将arp作为永久条目保存在对应表中.linux下可以用ifconfig –arp使得网卡驱动停用arp.
4)使用代理网关发送上行数据.
5)修改系统配置拒收ICMP重定向报文.









[网络通信面试]:http://www.cnblogs.com/wangwanchao/p/5268246.html
[IP地址子网掩码]:http://blog.csdn.net/gatieme/article/details/50989257
[腾讯后台开发面试题]:http://www.cnblogs.com/suncoolcat/p/3339624.html